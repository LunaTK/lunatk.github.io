{"pages":[],"posts":[{"title":"webpack:// 경로는 무엇일까?","text":"학교 아이캠퍼스 소스를 보다, 웹사이트 리소스에서 신기한걸 발견했다. 아이캠퍼스가 리액트로 만들어졌는데, 개발 모드로 열려있는지 소스가 다 보이는 것이었다.(아마 webpack-dev-server로 열어 놓은 것 같다) 평소 리액트 개발을 할 때 개발자 도구에서 원본 파일로 디버깅이 되는걸 당연시 했었는데, 사용자 입장에서 원본 파일이 보이니 갑자기 이상한 점이 눈에 띄었다. 파일 출처가 webpack:// 인데, 이게 뭐지?다른 파일들은 모두 URL 주소가 출처로 되어있었다. 그런데 저 리액트 앱 원본 코드들은(심지어 node_modules 폴더도 있다) 출처가 webpack://으로 되어있었다. 도대체 어떻게 가져왔길래 저렇게 표시가 되는지 원리가 궁금해 찾아보게 되었다. 여러가지 시도1. 일반 js 파일처럼 HTTP 요청을 통해 가져 올 것이다개발자 도구에서 일반 js 파일과 똑같이 보이니, 가져오는 방법도 일반 js 파일과 똑같을 것이란 생각이 먼저 들었다. 웹 사이트 내에서 불러오는 모든 리소스는 개발자 도구의 Network 탭에서 확인할 수 있다. 페이지 로딩이 다 끝난 후 확인 해 보니, webpack:// 디렉토리에서 확인할 수 있었던 수많은 js 파일이 단 하나도 없었다. 그래서 일단 webpack://이 뭔지 구글링을 해 보기로 하였다. https://github.com/angular/angular-cli/issues/11058 정확히 나와 똑같은 생각을 한 질문이 있었다. 해당 질문에서 얻은 내용을 정리해 보면 다음과 같다. webpack source map 에 쓰이는 커스텀 프로토콜이다 (나중에 알았지만 커스텀 프로토콜이 아니었다… 이 답변때문에 엄청 헷갈렸다) webpack-dev-server 와 관련이 있다 2. Source Map에 정보가 있을것이다위 답변을 통해 Source Map 과 큰 관련이 있다는 사실을 알 수 있었다. 그래서 우선 Source Map 이 무엇인지 검색해 보았다. 클라이언트측 코드를 결합하거나 최소화하거나 컴파일한 후에도 읽을 수 있고 디버그할 수 있게 합니다.소스 맵을 사용하여 소스 코드를 컴파일된 코드에 매핑합니다 정리하자면, webpack과 같이 원본 코드를 압축, 변형하는 경우 변형된 코드를 원본 소스코드를 보며 디버깅 할 수 있도록 변환된 파일을 원본 파일에 맵핑해 주는 파일이라고 한다. 맵핑할 js 파일 하단에 //# sourceMappingURL=http://example.com/sourcemap.map 과 같이 맵핑 파일의 URL을 넣어주면 자동으로 디버깅시 원본 소스코드를 보여준다고 한다. 위 사진처럼, Source Map detected 란 문구와 함께 맨 아랫줄에 주석으로 source map의 URL이 있는걸 확인할 수 있었다. 해당 URL로 들어가보니, 정신이 혼미해지는 source map 파일을 확인할 수 있었다. 현재 사용되는 소스맵은 스펙은 V3 버전인데, 다음과 같은 구조를 가진다고 한다. 12345678{ version : 3, file: \"out.js\", // source map 을 해줄 컴파일 된 js 파일 sourceRoot : \"\", // 원본 소스파일들 앞에 붙여줄 공통 경로 sources: [\"foo.js\", \"bar.js\"], // output file을 만드는데 쓰인 js 파일들 names: [\"src\", \"maps\", \"are\", \"fun\"], // javascript 안에 있는 함수, 변수 등의 이름 mappings: \"AAgBC,SAAQ,CAAEA\" // base64로 인코딩 된 실제 맵핑 테이블} 위 스펙에 따르면, webpack:///./public/javascripts/dummyl18nResource.js?1e80같은게 실제 파일이 있는 URL이어야 한다. 근데 경로에 . 이 들어가 있질 않나, webpack:// 같은걸로 시작하는 등 일반적인 URL 모양이 아니었다. 그래도 스펙이 그렇다 하니 일단 해당 URL로 접근 해 보았다. 역시나 안됬지만, 이건 뭐 되는게 더 이상했을 것 같다. 3. webpack 프로토콜이 있을것이다우리가 아는 일반적인 URL은 프로토콜://도메인:포트로 생겼다. 일단 webpack://의 생김새가 URL 처럼 생겼고, 실제로 그렇게 쓰여야 하니, 혹시 사이트 내에서 webpack이라는 커스텀 프로토콜을 정의한게 아닌가 생각이 들었다. 요새 웹은 정말 희안한 기능들이 많아서(ex. ws://), 충분히 가능할거라 생각하였다. 그리고 진짜 커스텀 프로토콜을 정의하는 기능이 있긴 있었다!! 하지만 깃허브 webpack, webpack-dev-server 저장소에서 검색을 해 봐도, 딱히 커스텀 프로토콜을 정의하는 부분을 찾을 수 없었다. 4. Source Map을 이용해 원본 소스코드를 다운해 보자개발자 도구에서 다른 사이트 Source Map이 보인다면 원본 소스코드를 다운할수 도 있다는건데, 이를 구현해놓은 코드가 없나 찾아보다 다음 포스팅을 발견했다. Extracting Javascript From SourceMaps 이분이 딱 내가 원하는 코드를 만들어서 github에 공개까지 해 놓으셨다 (denandz/sourcemapper) 그런데 Source Map 스펙에 따르면 분명 원본 파일을 다운받으려면 sources에 포함된 파일 하나당 한번의 HTTP 요청을 해야하는데, 위 소스코드에는 source map 파일을 받아오는 최초 한번의 HTTP 요청을 제외하고는 HTTP 요청이 없었다. 도대체 그럼 어떻게 원본 파일을 가져오는지 소스코드를 한번 다 읽어 보았다. 12345type sourceMap struct { Version int `json:\"version\"` Sources []string `json:\"sources\"` SourcesContent []string `json:\"sourcesContent\"`} 위 구조체가 sourceMap을 저장하는 구조체인데, sourcesContent 라는 처음보는 속성이 있었다. 구글링 해 보니, Source Map Revision 3 Proposal을 참고하라는 StackOverflow 게시글을 하나 찾을 수 있었다. 2019년 2월 19일에 추가된 스펙이었다. (그럼 그 이전에는 어떻게 소스맵을 제공했을까?) 하지만 스펙문서 설명이 너무 부실해서 저 내용만 봐서는 저게 정확히 무슨 기능인지 알기 어려웠다. 링크를 찾은 StackOverflow 게시글에 따르면, An optional list of source content, useful when the “source” can’t be hosted 아… 그러니까 선택적으로 Source Map 안에 Source Content, 즉 원본 소스코드를 넣을 수 있다는 말이었다… 원본 코드를 싹다 가지고 있어서인지, 저 소스맵 파일 하나의 용량이 20 메가바이트였다… 결론webpack:// 은 프로토콜이나 URL이 아니고, 그냥 웹팩이 임의로 파일 이름에 붙인 접두사 같은 것 이었다. 그리고 sources에 있는 파일 이름과 sourcesContent 에 있는 소스코드 내용이 순서대로 매칭되고, 실제 파일 내용을 sourcesContent에서 가져오더라도 sources 에 있는 파일 URL로부터 가져온것 처럼 개발자 도구에 표시가 되는 것이었다. 글로 정리하니 얼마 안되는 양이지만, 이걸 알아내는데 하루가 걸렸다. 소스맵이 W3C 표준은 아니라고 하는데, 왜 아닌지 알 것 같은 경험이었다😅","link":"/2019/10/21/20191021-what-is-webpack-path/"},{"title":"Node.js 에서 request 한글 깨짐 문제","text":"Node.js 에서 request 모듈을 사용하여 학교 홈페이지를 크롤링 하는 도중 한글이 깨지는 문제가 발생하였다. 사진1. 한글 깨짐 현상 한국인으로서 담담하게 받아들일 수 있는 현상이다. 확인해보니, Node.js는 UTF-8을 기본 인코딩으로 사용하는데 학교 홈페이지는 EUC-KR을 사용해서 글자가 깨지는 것 같았다. 사진2. 웹페이지 인코딩 확인 그래서 iconv 라이브러리를 이용해 EUC-KR 디코딩을 하게 해 주었는데, 이번엔 다른 문자로 글자가 깨졌다. 사진3. EUC-KR 처리 후 한글 깨짐 현상 원인그런데 이 占쏙옙 이라는 글자, 낯설지가 않은 사람들이 많을것이다… 문제를 해결하기에 앞서 왜 한글이 깨지면 저렇게 占쏙옙 이 미친듯이 반복되는지 궁금해 검색 해 보았다. 사진4. 출처 : https://namu.wiki/w/占쏙옙 정리하자면 다음과 같다. EUC-KR로 표현된 데이터가 UTF-8 인코딩으로 저장된다. 이때 UTF-8 범위를 벗어나 표현될 수 없는 문자는 모두 “표현 불가” 문자, 즉 � 로 치환된다. (사진 1) 이를 다시 EUC-KR로 취급하여 UTF-8로 변환하려 하면, 占쏙옙 이 된다. (사진 2) 이때문에 EUC-KR을 잘못 다루면 占쏙옙 파티를 볼 수 있게 되는 것이었다. 내가 겪은 문제는 아마 request 모듈에서 EUC-KR을 제대로 처리하지 않고 바로 UTF-8로 저장을 해서, 이미 � 으로 다 치환이 된 상태에서 EUC-KR 디코딩을 시도한게 원인인 것 같았다. 해결방법해결방법은 간단하다. request 모듈이 문자열 인코딩 처리를 안하게 해주면 된다. (즉 위의 1, 2번이 발생하지 않게 하면 된다) 12345678request({ url:\"http://icampus.ac.kr\" // 원하는 url값을 입력 ,encoding: null //해당 값을 null로 해주어야 제대로 iconv가 제대로 decode 해준다. } ,(err, res, body) =&gt; { // 생략 }}) 참고 : http://b1ix.net/322 야! 잘된다","link":"/2019/10/25/20191025-nodejs-request-encoding/"},{"title":"img 태그와 부모 태그의 높이가 왜 다를까?","text":"블로그에 URL 미리보기 기능을 만들던 도중 img 태그와 부모 태그의 높이가 다른 버그가 발생하였다. 빨간 부분 만큼 높이 차이가 발생 해당 HTML과 CSS는 대략 다음과 같다 html1234567891011&lt;div&gt; &lt;div class=\"og-image\"&gt; &lt;a&gt; &lt;img src=\"~~\"&gt; &lt;/a&gt; &lt;/div&gt; &lt;div&gt; &lt;!-- 웹사이트 요약 텍스트가 들어가는 부분 --&gt; &lt;/div&gt;&lt;div&gt; css1234567.og-image { background: red;}img { height: 120px;} 하지만 이상하게도 og-image 와 img 의 높이가 일치하지 않았다. 위는 비슷하게 구현해 본 코드이다.코드만 보면 img와 og-image의 높이가 같을 것 같지만, 실제 result를 보면 높이가 다르다. img 태그의 사이즈 (596.33 x 200) div.og-image 태그의 사이즈 (596.33 x 206) img를 a로 감싸서 그런가 a 태그를 제거해 보았지만, 여전히 오차가 있었다.혹시나 해서 og-image 의 높이를 직접 120px로 고정해 보니 img와 높이가 일치하긴 했다.하지만 responsive design을 적용 할 계획이라 높이를 고정시키지 않고 해결 할 필요가 있었다. 개발자 도구를 켜놓고 height, flex, max-height 등등 의심이 가는 원인을 다 건드려 보다, display옵션을 바꿔보던 중 버그가 해결되었다. 어떻게 해결 되었나 보니, img 태그의 display 값을 block 으로 바꾸니 해결되었던 것이었다. 문제를 해결한 JSFiddle 마치며img 태그의 display 속성 기본 값은 inline-block 이라고 한다 (그래서 width, height 값을 줄 수 있다고 한다). 근데 웃긴건 그렇다고 해서 다른 inline-block 속성을 준 태그에서 저런 문제가 발생하지는 않는다.(아마 img 태그는 좀 특별한 케이스의 inline-block인것 같다.) img 태그에서만 저런 문제가 발생하는것 같은데, 섬세한 관심이 필요한 친구인 것 같다. 기회가 되면 아래 링크의 img 태그 스펙을 자세히 살펴봐야 할것 같다. &lt;img&gt;: The Image Embed elementThe HTML img element embeds an image into the document. 사실 URL 미리보기가 잘 작동하는거 자랑할려고 괜히 한번 링크를 걸어보았다. 😏👍🏻","link":"/2019/10/28/20191028-html-img-parent-height/"},{"title":"Rollup & Svelte 에서 PurgeCSS 사용하기","text":"외주 프로젝트용 Web Component 개발에 UI 라이브러리를 사용하니, 빌드된 컴포넌트 사이즈가 너무 큰 문제가 발생해 PurgeCSS를 이용해 최적화를 해 보기로 하였다. 개발 환경은 다음과 같았다. Front-End Framework : Svelte Module Bundler : Rollup.js UI Library : Bulma 디자인을 전달받기 전이라 우선 UI 라이브러리를 사용하여 개발을 진행하였다.Rollup은 자바스크립트 번들러이기 때문에, 기본적으로는 진짜 자바스크립트 파일밖에 번들링을 못한다.따라서 .svelte, .css 파일을 번들링 하기 위해서는 적절한 플러그인을 적용해 주어야 한다. 1. Rollup Plugin 추가rollup.config.js123456789101112131415import svelte from 'rollup-plugin-svelte';import postcss from 'rollup-plugin-postcss';// 몇가지 Plugin을 더 사용했지만, 생략export default { input: 'src/index.js', output: [ { file: `public/${pkg.module}`, 'format': 'es' }, { file: `public/${pkg.main}`, 'format': 'umd', name } ], plugins: [ svelte(), postcss() ]} rollup-plugin-svelte 를 통해 .svelte 파일을 로드하고, rollup-plugin-postcss 를 통해 .css 파일을 로드할 수 있게 설정하였다. 이제 svelte 파일의 script 부분에서 Bulma의 css 파일를 import 할 수 있다. 2. svelte 컴포넌트에서 css 파일 import 하기component.svelte12345&lt;script&gt; import 'bulma/css/bulma.css'; //생략&lt;/script&gt;// Svelte HTML 부분 이렇게 해서 만들어진 컴포넌트는 아래처럼 생겼다. Svelte와 Bulma를 이용한 스마트폰 검색 Web Component 그런데 문제가 생겼다. css 파일을 import 하면 이를 string으로 바꿔서 통째로 번들링 해버리기 때문에, 쓰지 않는 속성까지 다 포함되어 용량이 너무 컸던 것이었다. Web Component 치고는 무거운 결과물 요즘 웹사이트 하나 webpack으로 빌드하면 기본이 몇 MB 이니, 260kb 정도면 작다 생각할 수 있지만, 이건 웹 컴포넌트로 쓸꺼라 최대한 줄일 필요가 있었다. 그래서 사용하지 않는 css 속성을 제거해준다는 PurgeCSS라는 툴을 사용해 보기로 했다. (이름이 ㅎㄷㄷ 하다. CSS 숙청…😦) PurgeCSS우선 PostCSS는 Webpack, Gulp, Grunt, Rollup 등 그냥 아무데나 다 갖다 쓸 수있고, 심지어 그냥 Standalone 으로도 쓸 수 있는 툴이다. 나는 빌드환경을 Rollup으로 잡아놓았기 때문에, 공식 사이트에 나와있는 Rollup 가이드를 확인해 보았다. updated 2020.04.11 : 현재는 페이지가 삭제되었다 PurgeCSS With Rollup 이게 끝이다. 그냥 저 페이지에 저거밖에 없었다… 정보가 너무 빈약해서 Configuration을 살펴보았다. Options1234567891011{ content: Array&lt;string | RawContent&gt;, css: Array&lt;string | RawContent&gt;, extractors?: Array&lt;ExtractorsObj&gt;, whitelist?: Array&lt;string&gt;, whitelistPatterns?: Array&lt;RegExp&gt;, whitelistPatternsChildren?: Array&lt;RegExp&gt;, keyframes?: boolean, fontFace?: boolean, rejected?: boolean} 중요한 부분만 보자면 다음과 같았다. content : css 사용 여부를 확인할 파일 (ex. html, js) css : 숙청할 css 파일 extractors : content에서 css selector를 추출해 주는 친구 whitelist : 사용되지 않더라도 숙청하지 않을 css selector 목록 With Rollup 가이드를 보면, content로 html 파일을 사용하고 있다. .svelte 파일도 사용 가능한지 공식 문서를 확인해 보았다. PurgeCSS provides a default extractor that is working with all types of filesbut can be limited and not fit exactly the type of files or css framework that you are using. 확인해 보니 Default Extractor로도 모든 파일이 다 된다고 한다(우와 개쩐다). 하지만 좀더 정확히 하려면 Custom Extractor를 만들어 쓰라고 한다. langbamit/purgecss-from-html 이라는 누가 만들어 놓은 Svelte용 Extractor가 있었다. 결론부터 말하면 이거 안써도 똑같이 잘 되서 처음엔 썼지만 마지막 단계에서는 그냥 안쓰기로 하였다. 이제 PurgeCSS를 Rollup에 적용해 보았다. rollup.config.js1234567891011121314151617181920212223242526import svelte from 'rollup-plugin-svelte';import postcss from 'rollup-plugin-postcss';import purgecss from 'rollup-plugin-purgecss';import PurgeSvelte from \"purgecss-from-svelte\";// 몇가지 Plugin을 더 사용했지만, 생략export default { input: 'src/index.js', output: [ { file: `public/${pkg.module}`, 'format': 'es' }, { file: `public/${pkg.main}`, 'format': 'umd', name } ], plugins: [ svelte(), postcss(), purgecss({ content: [\"./src/**/*.svelte\"], extractors: [ { extractor: PurgeSvelte, extensions: [\"svelte\"] } ] }) ]} 여기서 한방에 되면 재미가 없으니, 바로 오류를 뿜어주는 Rollup… CssSyntaxError 라는 키워드로 구글링을 하다 다음 StackOverflow 게시글을 발견했다 CssSyntaxError (1:1) Unknown word &gt; 1 | // extracted by mini-css-extract-plugin · Issue #358 · webpack-contrib/mini-css-extract-pluginmode: &amp;#39;production&amp;#39;, devtool: &amp;#39;#source-map&amp;#39;, plugins: [ new webpack.DefinePlugin({ &amp;#39;process.env.NODE_ENV&amp;#39;: JSON.strin… you have multiple loader for css please check your configuration css loader를 여러개 설정해서 생기는 에러라고 한다. 그래서 postcss 플러그인을 빼고 purgecss만 남겨보았는데, 또 에러가 발생하면서 안되었다. 좀더 구글링을 하던중, 어느 외국회사 GitLab이 떴다…! (다음에 GitLab 쓸일이 있으면 조심해야겠다…) 운이 좋게도 그곳에서 해답을 얻을 수 있었다. PurgeCSS를 Rollup Plugin이 아니라 PostCSS의 Plugin으로 만들어 놓은게 있었다 (FullHuman/postcss-purgecss). 성공한 Rollup 설정은 다음과 같다. rollup.config.js12345678910111213141516171819202122232425262728293031import svelte from 'rollup-plugin-svelte';import postcss from 'rollup-plugin-postcss';import Purgecss from \"@fullhuman/postcss-purgecss\"import PurgeSvelte from \"purgecss-from-svelte\";// 몇가지 Plugin을 더 사용했지만, 생략const purgeCss = Purgecss({ content: [\"./src/**/*.svelte\"], extractors: [ { extractor: PurgeSvelte, extensions: [\"svelte\"] } ]});export default { input: 'src/index.js', output: [ { file: `public/${pkg.module}`, 'format': 'es' }, { file: `public/${pkg.main}`, 'format': 'umd', name } ], plugins: [ svelte(), postcss({ plugins: [ purgeCss ] }), ]} PurgeCSS 적용한 결과물 File Size 결과는 감동적이었다. 264kb 에서 46kb로 무려 83% 감소하였다…😭 PurgeCSS 적용한 결과물 그런데 위 사진처럼 폰트가 좀 이상하게 나왔다. 확인해 보니 아래 selector가 날라갔다. 아마 Bulma 라이브러리가 폰트를 모든 Element에 적용하기 위해 body 태그에 적용했는데, .svelte 파일 내에서 body태그를 직접적으로 사용하는 부분이 없어서 안쓴다고 판단되 삭제된것같다. `body` selector로 폰트가 적용되어있다 `body` selector가 삭제되었다 그래서 PurgeCSS 의 whitelist에 body를 추가해 주었다. Solutionrollup.config.js123456789101112131415161718192021222324252627import svelte from 'rollup-plugin-svelte';import postcss from 'rollup-plugin-postcss';import Purgecss from \"@fullhuman/postcss-purgecss\"// import PurgeSvelte from \"purgecss-from-svelte\";// purgecss-from-svelte 는 안써도 문제 없다// 몇가지 Plugin을 더 사용했지만, 생략const purgeCss = Purgecss({ content: [\"./src/**/*.svelte\"], whitelist: ['body'] // whitelist 추가});export default { input: 'src/index.js', output: [ { file: `public/${pkg.module}`, 'format': 'es' }, { file: `public/${pkg.main}`, 'format': 'umd', name } ], plugins: [ svelte(), postcss({ plugins: [ purgeCss ] }), ]} 폰트가 성공적으로 잘 적용되었다. 빌드된 모듈 용량은 거의 그대로였다.","link":"/2019/11/09/20191109-purgecss-with-rollup-and-svelte/"},{"title":"Meteor에서 gRPC, DDP 사용하기","text":"Meteor는 Node.js 기반 Fullstack Web Framework이다. 이 글에서는 백엔드에서 프론트엔드 이외의 외부 클라이언트와 통신하는 기능을 추가하는 방법에 대해 이야기해 보고자 한다. Meteor는 기본적으로 웹소켓을 이용해 프론트엔드와 백엔드가 통신할 수 있는 기능을 제공한다. 이 기능을 통해 프론트엔드 개발을 할 때 MongoDB를 마치 서버에서 접근하듯이 손쉽게 다룰 수 있다. 하지만 이번 프로젝트 요구사항에는 프론트엔드, 백엔드가 아닌 제3의 클라이언트가 간단한 DB operation을 할 수 있는 기능이 필요하였다. 간단히 소개하자면, 실행이 오랫동안 걸리는 반복 수행 작업을 쉘 스크립트로 돌릴 때, 어느정도 진행되었는지를 Meteor 서버에게 알려주고 웹 프론트엔드로 모니터링 할 수 있는 서비스이다. 여러 조사 끝에 정리한 후보는 다음과 같다. RESTful API gRPC Distributed Data Protocol (DDP) 결론부터 말하면, 최종적으로 gRPC를 사용하기로 결정하였다. 아래 부터는 각각이 무엇이고, 어떤 장단점이 있는지 설명한다. RESTful API쉽게말해 HTTP GET, POST 요청등을 이용해 클라이언트와 서버가 소통하는 방법이다. 가장 흔하게 사용되는 방법이라 먼저 떠올랐지만, 다음과 같은 이유로 선정하지 않았다. Meteor에서 지향하는 방법이 아니다. Meteor는 Fullstack 프레임 워크라, 애초에 백엔드와 프론트엔드의 통합이 잘 이루어져 있는데, 특이하게 REST API가 아니라 웹소켓을 사용한다. 따로 REST API서버를 Meteor에 만들 순 있지만, 복잡해 보여 시도하지 않았다. 오버헤드가 클것같다. 실제 측정을 해본것은 아니지만, 아무래도 HTTP 프로토콜 레이어가 들어가니 다른 선택지에 비해 오버헤드가 있을것 같았다. gRPCgRPC는 구글에서 만들고 오픈 소스로 운영 중인 RPC(Remote Procedure Call) 프레임워크이다. 원래 RPC가 성능이 안좋던것을 개선해 지금은 REST API보다도 성능적으로 우세한것 같다.다음과 같은 이유로 선정하였다. 빠르다 grpcurl 이라는 커맨드라인용 툴이 존재한다. (심지어 go로 만들어서 빠르다!) 사용법일반적으로 Node.js에서 gRPC 서버 여는 방법을 따라하였다. (Node.js gRPC Services in Style) 다만 gRPC 서버를 Meteor에서 사용하려만 한가지 제약이 있는데, gRPC 서버에서 Meteor의 DB 함수를 사용하려면 Meteor.bindEnvironment 라는 함수로 래핑 해주어야 한다. 그렇게 복잡하지는 않고 코드 한두줄이 추가되는 정도이다. 자세한 내용은 Meteor code must always run within a Fiber 를 참고하였다. grpc.js12345678910111213141516const bound = Meteor.bindEnvironment((callback) =&gt; {callback();});const newSession = (call, callback) =&gt; { console.log(call.request); bound(() =&gt; { Tasks.insert({ title: call.request.title, createdAt: new Date(), }, (err, res) =&gt; { console.log(err, res); }); callback(null, { /* response data here */ }); });}; Distributed Data Protocol (DDP)공식 소개글 : Introducing DDP Meteor에 gRPC 올리는 방법을 찾아보다 알아낸 기능인데, 아마 이게 뭔지 아는사람은 거의 없을것 같다. Meteor 개발자팀이 만든 프로토콜로, Meteor의 프론트엔드와 백엔드가 웹소켓으로 통신할때 사용하는 프로토콜이다. 재밌는 점은 WebSocket 이라는것 자체가 웹 브라우저 밖에서도 쓸 수 있기 때문에, 그점을 이용해 Meteor와 아무상관없는 제3의 클라이언트에서도 미티어 백엔드와 DDP를 통해 통신할수 있다!! 사람들도 이미 DDP를 Remote Procedure Call(RPC)의 한 종류로 취급하고, 실제로 그렇게 쓰는 경우도 있어 보였다. 사실이라면 굳이 또다른 RPC인 gRPC를 도입할 필요가 없어보였다. DDP는 사람들이 다양한 언어에서 라이브러리로 구현해 놓았는데, 4년 전이 마지막 업데이트인게 대부분이었다… Meteor 와 다른 언어/플랫폼과의 통신 수단인 DDP 플랫폼 별 DDP Clients 그래서 Node.js로 구현한 DDP 클라이언트와 gRPC와 성능 비교를 해 보았다. MongoDB document를 10개 만드는데 걸리는 시간을 비교하였다. 121.69s user 0.41s system 42% cpu 4.954 total # DDP (node.js)0.10s user 0.07s system 82% cpu 0.204 total # gRPC (go) 결과는 DDP의 처참한 패배였다. DDP가 Node.js에서 돌아가긴 했지만, 감안하더라도 25배의 성능 차이는 용납할 수 없었다. DiscussionClient 입장에서의 실행 시간을 기준으로만 gRPC를 선택하였지만, 사실 Meteor 백엔드에 gRPC를 위한 서버가 하나 더 생기는 것이기 때문에 이 방법이 최선이라는 보장은 없다.또한 DDP 클라이언트는 node.js로 실험했기 때문에, 매번 스크립트 파싱, DDP 라이브러리 로드 등등 오버헤드가 커서 성능 차이가 더 심각한 것일수도 있다. 나는 어차피 요청 클라이언트를 쉘 스크립트 안에서 매번 다시 실행할것이기 때문에 위 실험 환경이 유의미 하지만, 지속적으로 돌아가는 클라이언트나 node.js가 아닌 다른 환경에서 실행하면 DDP의 성능이 gRPC에 비해 그렇게 나쁘지 않을수도 있다 생각한다. Conclusion구글이 만든 gRPC를 구글이 만든 go로 구현한게 최고인것 같다. 구글 만세 😊 References npm.js/ddp Node.js gRPC Services in Style Meteor code must always run within a Fiber grpcurl Introducing DDP Meteor 와 다른 언어/플랫폼과의 통신 수단인 DDP 플랫폼 별 DDP Clients","link":"/2020/04/11/20200411-meteor-grpc-ddp/"},{"title":"러스트 시작해보기","text":"요새 러스트가 핫하다고 해서 한번 배워보았고, 알고리즘 문제를 풀어보며 C++과 느낌이 어떻게 다른지 비교 해 보았다. Why Rust?요즘들어 파이썬이나 Node.js로 작업을 많이 하고 있었는데, 용량이 수십 MB, 수 GB 하는 데이터를 처리하다 보니 속도가 느린게 너무 심하게 체감이 되었다. 스크립팅 언어의 퍼포먼스 한계를 느끼면서, 네이티브로 컴파일되는 언어도 하나 배워야 할 필요성을 느끼게 되었다. 그래서 요즘 핫한 Go와 Rust 둘중에 고민하였는데, 결론부터 말하면 둘을 비교하는것 자체가 적절하지 않고, 어느 하나가 더 좋다고 할 수 없다고 느겼다. 이 둘이 목표로 하는 방향성 자체가 다르기 때문이다. Rust는 더 나은 C++을 지향하고, Go는 더 나은 Java를 지향한다고 한다(내 체감상으로는 Java보다는 Python과 비교하는게 더 맞는것 같다). 물론 단순 퍼포먼스만 보자면 Rust가 평균적으로 살~~짝 좋다고 한다 (Golang vs Rust 퍼포먼스 벤치마킹 썰). Rust와 Go를 비교하는건 다음에 해보기로 하고, 이 글에서는 Rust와 C++로 알고리즘 문제를 풀어보며 내가 느낀 차이점을 비교해 보려 한다. 알고리즘 문제 풀어보기알고리즘 문제는 백준에 올라와있는 간단한 BFS문제를 선택하였다(2178. 미로탐색). 둘의 코드가 최대한 비슷한 모양이 되도록 하기 위해 C++17으로 작성하였다. 나는 C++도 많이 안 다루어 보았고, Rust도 간단한 문법만 배우고 써본것이라 둘 다 적절한 코딩 스타일과 기능을 사용하지 않았을 수 있으니 감안하고 보면 좋을 것 같다… C++와 Rust로 작성한 코드(왼쪽: C++, 오른쪽: Rust) 약간의 줄바꿈 조절이 있긴 했지만, 둘 다 50줄 정도의 코드가 나왔고, 예상보다 C++과 Rust의 코드 모습이 그렇게 크게 다르진 않았다. 우선은 C++부터 살펴보고, 이를 Rust로 그대로 옮기면서 Rust 컴파일러가 뱉은 에러를 하나씩 살펴보며 Rust가 어떻게 Memory Safety를 제공하는지 생각해 보았다. C++ 풀이 위 코드는 테스트 케이스는 통과하긴 하는데, 백준에 제출하면 오답으로 뜬다. Rust 풀이 다음은 Rust로 코드를 옮기면서 겪은 어려움과 느낀점이다. 인풋 받는게 불편함scanf 같은 함수가 없어서 한줄을 받고 직접 파싱을 해야 했고, string이 int로 인덱싱이 안되서 as_bytes함수로 바이트 어레이로 바꾼 다음 한 바이트씩 뽑아야 했다. 다른건 몰라도 인풋받는거 때문에 알고리즘 문제를 푸는데는 C++이 나은것 같다. 메모리 접근에 대해 매우 깐깐함38, 39번 줄을 보면 visited, field 배열의 인덱스로 사용되는 nx, ny를 usize로 캐스팅 해서 쓰는것을 볼 수 있다. 이는 Rust가 강제하는 사항으로, 배열의 인덱스는 무조건 usize 타입이어야 한다. 또한 범위를 초과하는 인덱스로 접근하면 바로 크래시가 나며 프로그램을 종료한다고 한다. 알고리즘 문제라는 특수한 상황에서는 그럴일이 거의 없겠지만, 실제 프로그램 개발시에는 저런 문제로 메모리 접근 취약점이 발생할 수 있는데, C++로 풀때는 아무생각없이 signed integer를 인덱스로 사용했는데 Rust가 강제로 잡아주니 뭔가 나쁜 습관을 교정받는 느낌이었다. 값의 소유와 대여위 코드에서도 나와있는데, 1if (0..n).contains(&amp;nx) &amp;&amp; (0..m).contains(&amp;ny){ 부분에서 contains함수가 nx, ny 값을 변경하는거도 아닌데 레퍼런스로 값을 받고 있다. 이는 contains함수가 파라미터로 받은 값을 소유하게 되는것이 아니라 단순히 잠깐 빌려쓰기 때문이다. 또한 nx, ny는 immutable 하기 때문에, contains 함수는 값을 소유하지도, 변경하지도 않을 것이란것을 컴파일러가 알 수 있다. 소유권이라는 개념을 새로운 키워드 없이 레퍼런스라는 개념 위에 얹어 간단하게 구현한게 아주 신기했다. 그래도 C++과 Rust의 비슷한 점 일단 둘 다 표준 라이브러리가 Snake Case로 이름을 짓는다. 그리고 두 코드 모두 STL에 포함된 Deque를 썼는데, 둘의 메소드 이름이 거의 똑같았다 (e.g., push_back). 포인터와 레퍼런스 개념도 C++와 Rust가 거의 유사한것 같다. 다른점은 Rust에서 포인터(*)는 Unsafe 취급을 받고, 레퍼런스는 사용에 제약(소유, 대여)이 많다는 정도? C++17과 비교하면 문법적인 차원에서 큰 차이는 없는것 같다. Memory Safety가 잘 보장될까?정말 저런 단순한 아이디어로 Memory Safety가 보장될까? 라고 생각할 수 있다. 그런데 사실 위에 작성한 C++, Rust 코드는 Rust부터 작성하고 C++로 번역한 것인데, 신기한것은 Rust는 정답이라 뜨는데 C++는 몇몇 인풋에 대해 답은 뜨는데 메모리 에러가 뜬다. C++로 작성할때 일부러 메모리 접근에 큰 신경을 안쓰긴 했지만, 실제로 Rust 컴파일러가 이러한 문제점을 잘 잡아주는 것 같다. 흥미로우신 분들은 위 C++코드에서 메모리 문제가 발생하는 원인을 알아보아도 좋을 것 같다. Summary내가 느낀 Rust는 한마디로 정의하면 Memory safety가 추가된 Modern C++ 인것 같다. 언어차원의 Tuple, Range 지원 등을 제외하면 C++17에서도 람다함수, destructuring 등등 많은 현대적인 언어 기능을 지원하고 있어 문법적인 측변에서 차이는 그렇게 크지 않은것 같았다. 하지만 Memory Safety 관련해서는 깐깐한 과외선생님을 옆에 두고 코딩하는 느낌을 받았으며, 확실히 Rust 컴파일러가 제공하는 Memory Safety 교정을 받으면 안전한 프로그램을 만드는데 큰 도움이 될 것 같다고 느꼈다. 근데 너무 깐깐해서 크고 중요한 프로젝트가 아니면 그냥 Go 쓰는게 나을것 같다 😏. References Golang vs Rust 퍼포먼스 벤치마킹 썰 2178. 미로탐색","link":"/2020/07/24/20200724-starting-rust/"},{"title":"클로저에서 캡처된 변수는 어디 저장될까?","text":"클로저(Closure)는 자신이 생성(선언)된 외부 환경을 기억(Capture)하는 함수이다. 이 글에서는 Python, Javascript, Go가 각각 어떻게 이를 구현하는지를 알아보았다. 클로저에 대한 자세한 설명은 여기[1]를 참조하고 생략하고, 이 글에서는 클로저의 기능중 클로저 함수 외부에 선언된 변수를 접근하는 Capturing이 여러 언어에서 어떻게 구현되는지를 살펴보고자 한다. 여러 언어에서의 Closure우선 클로저를 지원하려면 언어 차원에서 함수를 일급 객체(First-class object)로 취급을 해야한다. 물론 함수가 일급 객체가 아닌 언어에서 클로저를 지원하는 경우도 있다. 그 예로 자바의 경우 Java8 부터 람다 함수가 도입되고 Closure를 사용할 수 있지만, 언어차원에서의 지원이 아니라 함수 하나당 그때그때 익명 클래스를 하나씩 생성하는 꼼수를 사용하며, final로 선언된 변수만 참조할수 있는 등 제약이 많아 완벽하다 할 수는 없다. 그래서 주로 동적 언어에서 잘 구현되어 있는데, 구글에 클로저를 검색하면 대부분 자바스크립트 언어에 대한 글이 나온다.아마 자바스크립트가 클로저를 제일 아름답고 직관적으로 쓸 수 있어서 그런것 같다. 특히 ES6부터 생긴 화살표 함수를 통한 currying[2]은 아주 아름다운 클로저를 만들어 낸다. 아래 코드는 자바스크립트에서 커링을 통해 클로저를 만들어내는 예시이다. closure.js1234567const makeAdder = (add) =&gt; (to) =&gt; add + to;const add2 = makeAdder(2);const add5 = makeAdder(5);console.log(add2(10)); // 12console.log(add5(10)); // 15 파이썬의 경우 언어차원에서 지원을 하긴 하는데… 파이썬으로 만들면 클로저가 뭔가 조잡해 보인다. 람다함수가 무조건 하나의 statement이어야 하는 제약때문에 한계도 많고, 무엇보다 안이쁘다. 위 코드를 파이썬으로 만들면 아래와 같다. closure.py1234567make_adder = lambda add: lambda to: add + toadd2 = make_adder(2)add5 = make_adder(5)print(add2(10)) # 12print(add5(10)) # 15 그런데 의외로 컴파일 언어인 Go에서 함수가 일급 객체이며, 클로저를 지원한다고 한다. 각각의 언어는 어떻게 캡처(Capture)한 변수를 저장할까? JavascriptJavascript 관련한 내용은 워낙 좋은 자료가 많은데, Toast에서 게시된 이 글[3]이 제일 잘 설명하고 있는 것 같으니, 꼭 한번 보길 권장한다. 자바스크립트는 함수가 선언되어 있는 Lexical Scope를 기억하며, 이 Scope 객체 안에 함수 내에 선언된 변수들이 저장된다. 용어가 무서운데, Dynamic Scope와 비교하면 이해하기 쉽다. Lexical Scope : 소스코드상의 위치를 기준으로 context 판단 Dynamic Scope : 실행 상태를 기준으로 context 판단 함수가 여러겹 겹쳐있을 수 있으니, Lexical Scope는 체인 형태로 함수가 내부적으로 가지고 있게 된다. 함수 내에서 변수에 접근하면, 제일 가까운 Scope부터 해당 변수가 선언되어 있는지 찾으며 마지막은 Global scope를 탐색한다. Javascript에서 Lexical Scope를 통해 변수를 찾는 과정 클로저에서 Capturing이 발생하면, 클로저가 속해있던 Lexical Scope를 클로저를 만들어 낸 함수가 종료된 후에도 체인에서 없애지 않고 유지한다. 이때 클로저에서 사용되지 않는 변수는 가비지 컬렉터에 의해 수거되어 Scope 객체에서 사라진다. Python파이썬에서는 함수도 객체(Object)이다. 파이썬은 인터프리터가 코드를 해석하면서 클로저에 Capture된다고 판단한 외부 변수는 함수 객체 내의 __closure__ 라는 특별한 변수에 저장한다[4]. 객체에 어떤 속성들이 있는지 확인하는 매직 메소드인 __dir__을 통해 클로저에는 __closure__라는 변수가 존재함을 확인할 수 있다. closure2.py1234567891011121314def outer_func(): msg = 'Hi' print('outer_func local variables :', locals()) def inner_func(): inner_var = 'Bye' print(msg) print('inner_func local variables :', locals()) return inner_funcmy_func = outer_func()my_func()print(my_func.__dir__()) 위 코드를 실행하면 아래와 같은 결과가 나온다. 1234outer_func local variables : {&apos;msg&apos;: &apos;HI&apos;}HIinner_func local variables : {&apos;inner_var&apos;: &apos;Bye&apos;, &apos;msg&apos;: &apos;HI&apos;}[&apos;__repr__&apos;, &apos;__call__&apos;, &apos;__get__&apos;, &apos;__new__&apos;, &apos;__closure__&apos;, &apos;__doc__&apos;, &apos;__globals__&apos;, &apos;__module__&apos;, &apos;__code__&apos;, &apos;__defaults__&apos;, &apos;__kwdefaults__&apos;, &apos;__annotations__&apos;, &apos;__dict__&apos;, &apos;__name__&apos;, &apos;__qualname__&apos;, &apos;__hash__&apos;, &apos;__str__&apos;, &apos;__getattribute__&apos;, &apos;__setattr__&apos;, &apos;__delattr__&apos;, &apos;__lt__&apos;, &apos;__le__&apos;, &apos;__eq__&apos;, &apos;__ne__&apos;, &apos;__gt__&apos;, &apos;__ge__&apos;, &apos;__init__&apos;, &apos;__reduce_ex__&apos;, &apos;__reduce__&apos;, &apos;__subclasshook__&apos;, &apos;__init_subclass__&apos;, &apos;__format__&apos;, &apos;__sizeof__&apos;, &apos;__dir__&apos;, &apos;__class__&apos;] 신기한점은 locals라는 로컬 변수를 출력하는 함수를 통해 확인해보면, 캡처된 변수도 일반 지역변수처럼 보인다는 것이다. 프로그래머의 편의성을 위한것으로 보이며, 실제로 저장은 __closure__에 된다. GoGo는 컴파일 언어답게, 이 문제를 컴파일러가 해결한다. 컴파일 하면서 선언된 함수 밖에서도 사용된다고 판단한 변수는 Stack이 아니라 Heap에 저장하게 한다고 한다. 신기한게 이 외에도 new를 통해 동적 할당한 메모리도 함수 내에서만 쓰이면 Stack에 할당하는 듯 힙 사용 최적화를 하는듯 하다[5]. 어떤 경우에 스택에 선언되고, 어떤 경우에 힙에 선언되는지는 여기[5] 잘 정리되어 있으니, 꼭 한번 보길 추천한다. Summary위 내용을 표로 정리하면 다음과 같다. 언어 저장위치 방식 Javascript Lexical Scope 체인 유지 캡처되지 않는 변수는 스코프 객체에서 제거 Python 함수 Object 내 __closure__ 필드 캡처되는 변수만 추가 Go Heap 메모리 컴파일 타임에 저장위치 결정 결국은 다 Heap에 저장한다. References1.클로저(closure)의 개념 ↩2.Currying in Javascript ↩3.자바스크립트의 스코프와 클로저 ↩4.파이썬 - 클로저 (Closure) ↩5.golang - 스택과 힙에 대해 ↩","link":"/2020/07/27/20200727-closure-and-free-vars/"},{"title":"VSCode에서 원격으로 gdb 디버깅하기","text":"macOS 환경에서 비주얼 스튜디오 코드를 통해 원격으로 리눅스 환경의 C/C++ 프로그램을 디버깅 해보자. Remote Debug를 통해 Remote Development 보다 가볍게 원격 환경에서 디버깅을 할 수 있다. PrefaceVisual Studio Code(VSCode)는 Remote Development[1] 플러그인을 통해 원격 머신에 연결해 마치 로컬 머신에서 VSCode를 사용하는 것 같은 인터페이스를 제공한다.이를 통해서 윈도우나 맥에서도 Docker나 SSH를 통해 리눅스에서와 똑같은 개발 환경을 경험할 수 있게 되었다. 올해 Remote Development가 업데이트 되면서 MacOS를 원격 환경으로 하여 사용할수도 있게 되면서, 집에 맥북을 두고 다니면서 어디에서든지 VSCode만 깔아서 내 맥북에서와 똑같은 개발 환경을 유지할 수 있게 되어 나도 아주 유용하게 사용하고 있다. 그런데 Remote Development 플러그인은 Remote OS에 VS Code Server라는 꽤 무거운 데몬 프로세스를 실행해야 한다는 단점이 있다. 그림 1. Remote Development Architecture 내가 사용중인 개발 환경은 Local OS(맥북)에 C 소스코드가 있고, 소스코드 폴더를 Docker 인스턴스인 Ubuntu에 마운트 해서 빌드와 실행만 Remote OS 내에서 할 수 있는 구조였기 때문에, 모든 개발 과정이 아닌 디버깅 과정만 Remote OS에서 진행할 수 있으면 충분하였다. 내가 고려한 원격으로 C/C++을 디버깅 하는 방법은 크게 두가지가 있다. CLion으로 원격 디버깅[2] 장점 : C/C++ 특화 IDE다 보니 디버깅 인터페이스가 좋지 않을까 싶다. 단점 : 이미 VSCode로 개발중인데 IDE가 하나 추가되고, CLion에서 프로젝트도 새로 생성해야 한다. 프로젝트에 C/C++ 언어만 사용중인게 아니라 다양한 언어 지원이 중요하였다. VSCode로 원격 디버깅 장점 : 이미 사용중이라 gdb를 원격으로 연결만 하면 된다. 단점 : 디버깅 인터페이스가 CLion보다는 하급인것 같다. 디버깅에 뭐 거창한 기능을 바라는게 아니라 그냥 쓰고있던 VSCode에서 원격으로 gdb 연결하는 방식을 선택하였다. 말이 원격으로 gdb 연겷하는 것이지, 개발자 입장에서는 로컬 IDE에서 디버깅 하는것처럼 VSCode에서 브레이크 포인트도 걸 수 있고 다 할 수 있다. 내부적으로 gdb를 쓰는지는 설정할 때 빼고는 크게 체감은 안된다. 설정 환경 Local machine macOS Catalina 10.15.6 GNU gdb (GDB) 9.2 VSCode 1.47.3 Remote machine Ubuntu 20.04 LTS (Docker instance) docker desktop community 2.3.0.4 GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1 VSCode Remote Debugger 연결하기맥북 VSCode에서 Remote OS에 gdb를 연결하기 위해서는 크게 세가지 단계가 필요하다. macOS에 gdb 설치 linux에 gdbserver 설치 macOS에 VSCode 설정 여러 포스팅을 참고 하였는데[3][4][5], 안되는 부분들이 몇 있어서 조금씩 수정하면서 진행하였다. macOS에 gdb 설치VSCode는 gdb가 내장되어 있지 않기 때문에, 따로 설치를 해야한다. macOS에는 기본적으로 gdb가 없는것 같은데, 나는 homebrew를 통해 최신버전을 설치를 해 주었다. 1$ brew install gdb 참고: macOS에서 linux 바이너리를 디버깅 해야하기 때문에 다른 포스팅들을 보면 brew install gdb --with-all-targets 를 통해 모든 아키텍쳐 정보를 포함하게 gdb를 설치하라 하는데, 나는 저렇게 하면 --with-all-targets 플래그에서 에러가 났다. 그래서 플래그 없이 설치했는데 잘 되는거 보니 최신 버전에는 기본적으로 모든 아키텍쳐 데이터가 포함되나 보다. 이때 설치 이후에도 두가지를 더 신경써야 한다. 1. 기본 설치되어 있는 gdb 링크 업데이트brew install gdb 이후 출력하는 메세지를 잘 보면, 이미 /usr/local/bin/gdb 파일이 존재하는 경우 brew는 새로 설치된걸로 덮어쓰기를 하지 않는다. 그래서 직접 이를 overwrite 해주어야 한다. 1$ brew link --overwrite gdb 2. gdb에 codesign 적용디버깅은 커널 권한을 사용하기 때문에, macOS에서는 프로그램에 서명을 해야 정상적으로 사용할 수 있다. 이 과정이 어렵진 않은데 좀 길기때문에, 기회가 되면 다음에 따로 포스팅을 하도록 하고 중요한 부분만 짚고 넘어가도록 하자. self-signed 인증서 발급 후 gdb 바이너리 파일 서명 https://sourceware.org/gdb/wiki/PermissionsDarwin[6] .gdbinit 설정 macOS 10.12 (Sierra) 부터는 gdb 7.12.1 이상을 사용해야 하고, 아래 옵션을 gdb를 실행하고 입력해 적용시켜 줘야 한다. set startup-with-shell off 또는 홈 디렉토리에 .gdbinit 파일을 만들어서 해당 옵션을 적어 놓으면 자동으로 gdb를 실행할때마다 적용한다.1set startup-with-shell off 2번까지 완료했으면 hello world 를 만들어서 디버깅이 되나 확인해보도록 하자. linux에 gdbserver 설치Linux에서는 원격 디버깅을 열어주는 gdbserver*를 설치해야 하는데, *gdb 패키지에 내장되어 있기 때문에 gdb가 깔려있으면 따로 설치할 필요가 없고, 안깔려 있으면 다음 명령어를 통해 설치해 주면 된다. 1$ sudo apt install gdb 그다음 디버깅을 할 바이너리 파일을 gdbserver로 열어놓으면 된다. 1$ gdbserver :9091 ./path/to/binary arg1 arg2 ... 당연한 얘기지만 :9091에서 포트는 꼭 9091일 필요는 없으며, command line arguments가 있으면 바이너리 파일을 명시한 이후 순서대로 적어주면 된다. 다음과 같은 메세지가 뜨면 성공! 12Process ./path/to/binary created; pid = 171Listening on port 9091 그리고 디버깅 세션이 끝나면 gdbserver가 꺼지기 때문에, VSCode에서 디버깅을 실행하기 전 매번 다시 위 명령어를 실행해야 한다. (계속 켜놓는 옵션이 있는지는 모르겠다) macOS VSCode에서 디버깅 설정소스코드 파일을 보면서 디버깅을 하기 위해서는 당연한 얘기이지만, 소스코드가 있어야한다 (로컬에도 있어야 한다). 바이너리 파일은 로컬, 리모트에 둘다 있어야 하는데 소스코드는 로컬에만 있으면 되는것 같다. 우선 나는 Local OS에 있는 소스코드 폴더를 Docker에 마운트 시킨 상태이기 때문에, 모든 파일이 공유되고 있는 상황이다. 클라우드 서버로 원격 디버깅을 하는 상황 등에서는 rsync, sshfs, nfs 등을 사용해 파일을 동기화 시키는 방법을 주로 쓴다고 하는데, 내생각에는 실시간 파일 동기화는 필요 없기 때문에 미리 옮겨놓는 정도면 충분할 것 같다. 아래 그림에서 1번을 누르면 디버깅 메뉴가 뜬다. 2번을 누르면 launch.json 파일이 생성되고, 편집기로 열어준다. 그림 2. Debug Configuration 추가 configurations 필드에는 어레이가 들어가는데, 다음과 같은 json 오브젝트를 추가해 주자. launch.json12345678910111213141516171819202122232425{ \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"My Remote Debug\", \"type\": \"cppdbg\", \"request\": \"launch\", \"program\": \"${workspaceRoot}/path/to/bin\", \"miDebuggerServerAddress\": \"localhost:9091\", \"stopAtEntry\": false, \"cwd\": \"${workspaceRoot}/path/to/src\", \"environment\": [], \"externalConsole\": true, \"linux\": { \"MIMode\": \"gdb\" }, \"osx\": { \"MIMode\": \"gdb\" }, \"windows\": { \"MIMode\": \"gdb\" } } ]} 이때, program, miDebuggerServerAddress, cwd 세개의 필드가 중요하다. program local에 있는 바이너리 파일의 경로를 써주어야 한다. miDebuggerServerAddress 원격 서버의 IP 주소와 gdbserver를 실행항때 사용한 포트를 적어주어야 한다. 나는 docker 포트 매핑을 하였기 때문에 localhost를 IP로 사용하였다. cwd 이 경로를 기준으로 소스코드 파일을 찾으며, 컴파일 할때의 상대경로를 기준으로 한다. 쉽게 생각해서 컴파일을 수행한 cwd와 일치시켜주면 된다. 디버깅 시작하기gdbserver를 시작하고, VSCode에서 추가한 설정으로 디버깅을 시작하면 gdbserver 에서 다음과 같은 메세지가 뜨면 성공이다. 123Process ./path/to/binary created; pid = 178Listening on port 9091Remote debugging from host 172.17.0.1 그림 3. Debugging 시작 성공! 이제부터는 평소 IDE에서 디버깅 하던대로 하면 된다 😉 References1.VS Code Remote Development ↩2.Remote Debug via GDB/gdbserver Of CLion With Docker ↩3.How to Debug Programs on Remote Server using GDBServer Example ↩4.Remote gdb from MacOS X to Linux with C++ STL pretty-printing ↩5.Remote debugging of C/C++ code with Visual Studio Code ↩6.PermissionsDarwin ↩","link":"/2020/08/10/20200810-vscode-remote-gdb/"},{"title":"쉘스크립트로 웹사이트 모니터링 툴 만들기","text":"웹사이트 내의 정보 업데이트를 자동화 하여 모니터링하면 편한 경우가 많다. 나는 주로 파이썬이나 node.js를 이용해 모니터링 툴을 만들었는데, 문득 쉘스크립트를 통해 훨씬 단순하게 구현할 수 있겠다는 생각이 들어 만들어 보았다. *이 글에서 소개하는 방법은 크롤러라 하기에는 기능이 너무 단순해 모니터링 툴 이라는 용어를 사용하였다. * 아마 대부분의 모니터링 툴들은 아래와 같은 순서를 따를것이다. HTTP 요청을 통한 웹사이트 데이터 가져오기 데이터 전처리를 통해 필요한 부분 추출하기 업데이트가 있는지 이전 데이터와 비교하기 업데이트가 있을시 사용자에게 알림 보내기 그동안에 파이썬이나 node.js로 위같은 일을 하는 코드를 구현하기 위해 준비단계가 좀 길었다. 프로젝트 폴더 만들고 npm init 하고 dependency 설치하고… 그렇게 node.js로 만든 코드는 각 부분을 아래와 같은 방법으로 구현하였다. HTTP 요청 request 라이브러리 데이터 전처리 javascript 코드 업데이트가 있는지 이전 데이터와 비교 mongodb 사용 업데이트 알는 nodemailer 이용, 이메일로 알림 전송 위 과정 반복 pm2로 백그라운드 실행 mongodb 사용은 약간 오버스러운 느낌이 있지만, 그걸 제외하더라도 단순한 모니터링 작업 하나를 위해서 꽤 많은 라이브러리와 코드가 들어갔었다. 그런데 쉘스크립트를 공부하다 보니 저정도 기능이면 굳이 파이썬이나 node.js 쓰면서 라이브러리를 덕지덕지 가져다 쓸 필요도 없겠다는 생각이 들었다. 쉘스크립트 구현쉘스크립트로 만들때는 각 부분을 아래와 같은 방법으로 구현하였다. HTTP 요청 curl를 통해 REST API 요청 데이터 전처리 jq를 통해 JSON 전처리 업데이트가 있는지 이전 데이터와 비교 텍스트파일로 저장 업데이트 알림 terminal-notifier 위 과정 반복 cron 데이터 전처리를 위해 터미널 JSON 프로세서인 jq, 맥북에서 알림을 띄워주는 프로그램인 terminal-notifier 정도만 추가로 설치하였고, curl, cron 같이 대부분의 기능은 리눅스나 macOS에서 기본 제공하는 터미널 명령어로 해결이 가능했다. 사용한 명령어각 명령어를 사용한 이유는 아래와 같다. curl 터미널에서 HTTP 요청 하는데 별다른 방법이 있나 싶다 jq 내가 모니터링 할 사이트는 운좋게도 내부적으로 REST API 엔드포인트를 가지고 있었다 리스폰스 데이터가 json이라 터미널용 JSON 프로세서인 jq를 사용하였다 개발자들 가져다 쓰라고 오픈해놓은건 아니지만 사용에 딱히 제약은 없어보여서 찾아내서 사용하였다 만약 리스폰스 데이터가 HTML이거나 하면 다른 프로세서 툴을 사용하면 될것같다 terminal-notifier 원래 구현대로 mail 보내는 방법도 생각해 보았다. curl로 gmail 보내는 방법도 있긴 하였지만[1], 생각해보니 메일로 알림은 핸드폰으로 오는데 알림을 주로 보는 시간대는 내가 맥북을 쓰고있을때라 맥북 알림으로 오는게 더 좋을것 같았다. 실제로 써보니 맥북 알림이 훨씬 편하였다 cron 쉘 스크립트 자체에 sleep을 주고 백그라운드에서도 실행하는 방법이 있겠지만, cron을 쓰는게 더 깔끔하고 매번 부팅할때마다 다시 실행할 필요가 없어서 선택하였다. 코드아래는 실제 작성한 코드이다. 우리학교 공지사항에서 새 소식이 있는지 API 요청을 통해 알려주는 코드이다.(공개하는데 문제가 있을 시 삭제할수도 있음) crontab 설정할때는 쉘 스크립트에서 실행할 바이너리 파일을 찾을 PATH 경로를 따로 명시해 주어야 했다. corntab 설정 파일은 아래와 같다. 1234PATH=&quot;/usr/local/bin:/usr/bin:/bin:$PATH&quot;NOTICE_PATH=&quot;/Users/LunaTK/Developer/notice-crawler&quot;*/10 * * * * cd $NOTICE_PATH &amp;&amp; $NOTICE_PATH/notice-crawler.sh &gt;&gt; $NOTICE_PATH/log.txt 2&gt;&amp;1 cron으로 10분마다 실행되게 하였고, log.txt에 업데이트가 있을시 기록하게 설정하였다. 장점이 모니터링 코드는 원래 node.js로 만들어 놓았던게 있었는데, 쉘스크립트로 다시 구현해보면서 느낀 장점은 아래와 같다.링 관심사 분리가 터미널 명령어로 자연스럽게 되어서 코드가 훨씬 깔끔하다 HTTP요청은 curl, 데이터 전처리는 jq, 알림은 terminal-notifier 각 부분을 연결하는 코드만 쉘스크립트로 작성 왠지 터미널 빡고수가 된듯한 느낌이 들어 기분이 좋다 여러 부분에 응용해서 써먹으면 좋을것 같다. References1.https://stackoverflow.com/questions/14722556/using-curl-to-send-email ↩","link":"/2020/09/20/20200920-web-monitoring-in-shellscript/"},{"title":"모던 CLI 툴 추천 리스트","text":"리눅스나 macOS에서 터미널을 사용하다 보면 CLI 명령어를 자주 사용하게 된다. 대부분의 강의나 포스팅에서는 초창기부터 있던 전통적인 CLI 툴 위주로 알려주는데, 요즘에는 더 이쁘고 빠르고 편한 툴들이 많이 나와서 괜찮은 것들을 한번 정리해 보았다. 아래 나열된 툴들 대부분은 기존 CLI 명령어를 대체, 개선하고자 만들어졌다. 그래서 제공하는 기능과 목표는 비슷하지만, 조금씩 다른 명령어 인터페이스를 제공한다. 또한 모두 공통적으로 colorized output을 제공하여 시각적 만족도가 높다. exa https://github.com/ogham/exa 현대판 ls 컬러 하이라이트, tree 모드 등을 제공한다 나는 exa를 ls로 alias해서 사용하는데, 아주 만족스럽다 😎 ripgrep https://github.com/BurntSushi/ripgrep 현대판 grep grep보다 훨씬 빠르다고 하다 regex 친화적인 검색 (Rust 내장 regex 엔진 사용) fd https://github.com/sharkdp/fd 현대판 find find보다 더 빠르다고 하다 jq https://github.com/stedolan/jq 커맨드라인 JSON 프로세싱 툴 JSON path를 통해 입력된 JSON에서 특정 필드를 추출하는 등의 작업 가능 curl과 pipe하여 REST api 리스폰스를 파싱하기 좋음 속도와 표현력이 좋다 fx https://github.com/antonmedv/fx jq와 비슷한 JSON 프로세싱 툴 jq는 C언어로 작성되었는데, fx는 node.js라서 좀 더 느리다 대신 nodejs 3rd-party 라이브러리를 쓸 수 있어 jq보다 확장성이 좋다 기본 기능만 봐서는 jq가 더 좋아보임 interactive mode, streaming 등 지원 httpie https://github.com/httpie/httpie 현대판 curl 쉽고 사람 친화적인 사용성을 지향한다 curlie https://github.com/rs/curlie curl 인터페이스로 wrapping 해놓은 httpie 아웃풋은 httpie지만 인풋, 옵션 등 사용법이 curl과 동일 bat https://github.com/sharkdp/bat 현대판 cat 줄번호 표시, syntax highlight 등등 nnn https://github.com/jarun/nnn 터미널 파일 매니저 (터미널에서 쓰는 탐색기라고 보면 된다) 보통 mv, cp, mkdir 등등 명령어를 개별로 써야하는데 nnn 속에서 단축키로 여러 작업 가능 ranger https://github.com/ranger/ranger nnn이랑 비슷, 터미널 파일 매니저 좀 더 기능이 많고 복잡하다 python으로 구현되어있어 좀 느리다 tldr https://github.com/tldr-pages/tldr 현대판 man … 보다는 특정 명령어로 자주 사용하는 예제만 보여주는 man Community driven이라 사람들이 추가한 커맨드에 대한 정보만 나온다 fzf https://github.com/junegunn/fzf fuzzy finder라고, 검색한 문자열로 매칭될 수 있는 모든 파일, 커맨드 히스토리 등을 찾아줌 부분 매칭, 전체 매칭 등 아주 강력하다 원래 터미널에는 없는 기능인데, 진짜 사기적으로 편하다. 다른건 몰라도 이건 꼭!! 설치하는것을 추천 특히 커맨드 히스토리 찾는 기능이 정말 편하다 여기서 소개한 툴 중 유일하게 한국인이 만들었다 🇰🇷","link":"/2020/09/10/20200910-modern-cli-tools/"},{"title":"애플 M1 맥이 그렇게 빠른 이유","text":"M1 맥 출시 이후, 여러 벤치마킹 수치와 실사용기들이 M1 맥의 압도적인 성능을 이야기 하고 있다.어떻게 갑자기 이렇게 강력한 하드웨어의 등장이 가능했을까? 압도적인 M1 칩의 성능이 밝혀지면서 이제는 호환성 문제만 해결되면 무조건 M1 맥으로 옮겨가는게 당연하다는 의견이 주류가 되었다. M1 맥 싱글코어 벤치마킹, 데스크탑과 랩탑을 통틀어 최상위권이다. 또한 애플이 제공하는 맥 전용 소프트웨어(ex. 파이널컷)들은 이미 M1 맥북에 최적화가 되어 있기 때문에, 주로 사용하는 소프트웨어가 그런것들인 맥북 사용자들은 당장 오늘 M1 맥북으로 갈아타는게 합리적으로 보일 정도이다. 그런데 ARM 프로세서 기반 CPU를 탑재한 랩탑의 출시는 M1 이전에도 여러번 있었지만, 이정도의 압도적 성능을 보여주진 못하였다. 대체 M1은 어떻게 이런 비약적인 성능 발전을 가져올 수 있었는지 설명한 좋은 글이 있어 번역해 보았다. 원문 : Why Is Apple’s M1 Chip So Fast? 옮긴이의 들어가기 전 짤막 지식원문 글에서도 완~전 기본적인 내용은 설명하지 않는데, 들어가기 전 사전 지식을 간단히 짚어보자. 맥북은 지금까지는 Intel 기반 CPU를 사용해 왔는데, 여러가지 문제 (업그레이드 느림, 발열 문제)가 있어왔어서 자체 개발한 M1 칩으로 갈아타는것을 발표하였다. M1에서 사용하는 CPU는 ARM 프로세서 기반이다. 현대 CPU는 크게 두가지로 나뉜다, RISC vs CISC RISC (Reduced Instruction Set Computer) : ARM에서 주로 사용. 쉽게생각해 CPU가 실행하는 instruction 형태와 갯수가 단순하다. Instruction마다 길이가 같다. CISC (Complex Instruction Set Computer) : Intel, AMD에서 주로 사용. 쉽게 생각해 CPU가 실행하는 instruction 형태와 갯수가 복잡하다. Instruction마다 길이가 다르다. Why Is Apple’s M1 Chip So Fast?저는 작년에 유튜브에서 4000 달러 정도를 들여 40GB 램이 장착된 iMac을 구입한 사람을 보았습니다. 올해는 그사람이 그 값비싼 iMac이 자기가 고작 700 달러 주고 산 새 M1 Mac Mini에게 처참히 무너지는지 눈물흘리며 보고 있었습니다. 여러 실 사용 테스트를 보면, M1 맥은 지금까지의 하이엔드 인텔 맥을 앞서는 정도가 아니라 그냥 부숴버리고 있습니다. 이런 믿을수 없는 모습에 사람들은 도대체 어떻게 이런게 가능한지 의문을 가지고 있습니다. 여러분도 그런 생각을 가지고 있었다면, 딱 알맞은 곳에 찾아오셨습니다. 이 글에서는 애플이 M1을 가지고 정확히 무엇을 했는지 몇가지 이해하기 쉬운 부분들로 나누어 설명해 보고자 합니다. 구체적으로, 아마 여러분들은 아래와 같은 의문을 갖고 있을 것 입니다. M1 칩이 그렇게 빠를 수 있는 기술적인 이유? 이걸 위해 애플이 아주 기상천외한 기술을 사용했는지? (역자: 외계인 고문?) 인텔이나 AMD가 비슷한 기술을 가져와서 경쟁을 시작할 가능성이 얼마나 되는지? 물론 이러한 질문들을 구글링 해 볼수 있겠지만, 애플이 무엇을 했는지 표면적인 설명을 넘어 이해하려 한다면 Instruction Decoders, Reorder Buffer 등등 매우 기술적인 이야기들에 둘러쌓여 버릴 것 입니다. 여러분이 CPU 하드웨어 오타쿠가 아니라면 이런 내용은 그냥 이해할 수 없는 이야기겠지요. 이 이야기를 제대로 이해하려면 제가 이전에 쓴 글을 읽어보는것을 추천드립니다: “What Does RISC and CISC Mean in 2020?“. 해당 글에서는 microprocessor (CPU)가 무엇인지, 그리고 아래와 같은 몇가지 중요한 컨셉을 설명하고 있습니다. Instruction Set Architecture (ISA) Pipelining Load/Store architecture Microcode vs Micro-operations 읽기 귀찮다면, 이글에서도 짧게나마 제가 쓴 M1칩에 대한 설명을 이해하는데 필요한 내용들을 알려드리겠습니다. Microprocessor (CPU)란 무엇인가?일반적으로 인텔이나 AMD에서 제조한 칩(Chip)에 대해 이야기 할때, 이는 Centrual Processing Units (CPUs) 또는 Microprocessors를 가리킵니다. 제가 쓴 글 RISC vs. CISC story 에서 알 수 있다 시피, 이들은 메모리에서 명령어(instruction)를 불러(pull) 옵니다. 그 다음 일반적으로 각 instruction은 몇몇 과정을 거치게 됩니다. 매우 기본적인 RISC CPU (M1 아님). Instruction은 파란 화살표를 따라 Memory에서 Registers로 이동됨. Decoder는 각 instruction이 무엇인지 판단하고, 빨간 화살표로 표시된 Control Lines를 통해 CPU의 여러 파트를 활성화 함. ALU는 Registers에 위치한 값들에 덧셈이나 뺼셈을 수행함. CPU는 가장 기본적인 수준에서 보면, 레지스터(register)라 불리는 개별 이름이 있는 메모리 구역 (memory cell) 여러개와 산술 논리 장치 (arithmetic logic unit, ALU)라 불리는 연산 유닛 여러개로 이루어진 장치입니다. ALU는 덧셈, 뺄셈, 그리고 다른 기본적인 수학적인 연산을 수행합니다. 하지만 이들은 CPU에만 연결되어 있습니다. 두개의 숫자를 더하기 위해서는, 이 두 숫자를 메모리로부터 CPU 내부의 두개의 레지스터로 가져와야 합니다. 아래는 M1이 수행하는 전형적인 RISC CPU 연산입니다. 1234load r1, 150load r2, 200add r1, r2store r1, 310 여기서 r1, r2는 앞서 언급한 레지스터입니다. 현대 RISC CPU는 레지스터에 없는 숫자로는 연산을 수행하지 못합니다. 예를 들어 RAM 위의 두곳의 다른 위치에 있는 숫자를 더하는것은 불가능 합니다. 대신, 두 숫자를 불러와서(pull) 개별적으로 레지스터에 저장한 다음에 해당 레지스터에 들어있는 값 끼리 더하는것은 가능합니다. 그리고 위 예제에서 수행하는것이 바로 그것입니다. 먼저 RAM위의 메모리 위치 150에 존재하는 값을 불러와 CPU 내의 r1 레지스터에 저장합니다. 그 다음 메모리 주소 200에 위치하는 값을 불러와 r2 레지스터에 저장합니다. 그 다음에야 비로서 두 숫자는 add r1, r2 instruction을 통해 더해질 수 있습니다. 두개의 레지스터 (accumulator register와 input register)를 가지고 있는 옛날 기계적 계산기. 현대 CPU들은 일반적으로 열개가 넘는 레지스터를 가지고 있고, 기계적인게 아니라 전기적이다. 레지스터라는 컨셉 자체는 오래된 것입니다. 그 예로, 위 사진에 나온 옛날 기계적 계산기는 덧셈에 사용될 두 숫자를 들고있는 두개의 레지스터를 가지고 있습니다. 이 용어는 아마 cash register (우리말 금전 등록기, 카운터에서 지폐,동전 넣는것)에서 유래한 것으로 보입니다. 레지스터는 인풋으로 쓰일 숫자를 등록(register)하는 곳 입니다! M1은 CPU가 아닙니다!여러분이 M1에 관해 알아야 할 아주 중요한 사실이 있습니다. M1은 CPU가 아니라, 여러개의 칩이 하나의 거대한 실리콘 패키지에 넣어진 전체적인 시스템 입니다. CPU는 그 여러가지 칩들 중 하나일 뿐 입니다. 기본적으로, M1은 하나의 칩에 올려진 하나의 온전한 컴퓨터 입니다. M1은 CPU, 그래픽 처리 유닛 (graphical processing unit, GPU), 메모리, input &amp; output 컨트롤러, 그리고 컴퓨터를 구성하는 많은 다른 요소들로 이루어 져 있습니다. 이것이 바로 System on a Chip (SoC)이라고 불리는 것 입니다. M1은 System on a Chip 이다. 즉, 컴퓨터를 이루는 모든 구성요소가 하나의 실리콘 칩 위에 올라가있다. 오늘날 인텔이나 AMD로부터 칩을 구입하게 된다면, 실제로 받게 되는 것은 여러개의 microporcessor가 하나의 패키지에 포함된 것입니다. 예전에 컴퓨터는 물리적으로 분리된 여러개의 칩을 마더보드(메인보드)에 가지고 있었습니다. 컴퓨터 마더보드의 예시. 메모리, CPU, 그래픽 카드, IO 컨트롤러, 네트워크 카드, 그리고 많은 다른 구성요소들이 서로 통신하기 위해 마더보드에 연결된다. 하지만 요즘에는 엄청난 수의 트랜지스터를 실리콘 다이 (silicon die) 하나에 넣을 수 있기 때문에, 인텔이나 AMD같은 회사들은 여러개의 microprocessor를 하나의 칩 안에 넣기 시작했습니다. 이러한 칩들은 CPU 코어 라고 불려 집니다. 하나의 코어는 기본적으로 메모리로부터 instruction을 읽어와 연산을 수행할 수 있는 완전히 독립적인 하나의 칩 입니다. 여러개의 CPU 코어를 가지는 하나의 마이크로칩(microchip) 이것이 바로 오랜 시간동안 성능 향상이라는 게임에서 주된 요소였습니다. 즉, 성능 향상은 그냥 범용 CPU 코어(general-purpose CPU cores) 갯수를 늘리는 것 이었습니다. 하지만 그러한 트렌드에 변화가 있었습니다. 바로 CPU 시장에서의 한 플레이어가 이러한 트렌드에서 벗어나기 시작한것입니다. 애플의 그렇게 비밀스럽지 않은 혼합적 컴퓨팅(heterogeneous computing) 전략범용 CPU 코어를 계속 늘려나가는 것 대신, 애플은 다른 전략을 수립하였습니다. 바로 더 특화된 소수의 일을 하는 특화된 칩을 더 많이 추가하는 것입니다. 특화된 칩의 장점은 범용 CPU 코어에 비해 전력은 훨씬 덜 소모 하면서 일은 훨씬 더 빨리 할 수 있다는 것입니다. 이는 완전히 새로운 지식은 아니었습니다. 지난 수년간 GPU 같은 특화된 칩들은 Nvidia와 AMD 그래픽 카드에 올라가 그래픽에 관련된 연산들을 범용 CPU들보다 훨씬 더 빨리 처리해 왔습니다. 애플이 한 것은 이걸 좀 더 과격하게 한 것 이었습니다. 그냥 범용 코어와 메모리를 몇개 갖는 대신, M1은 아래와 같이 매우 다양한 특화 칩들을 가지고 있습니다. Central processing unit (CPU) - SoC의 “두뇌” 역할. 운영체제나 어플리케이션에 사용되는 대부분의 코드를 돌림. Graphics processing unit (GPU) - 앱의 UI 표시, 2D/3D 게이밍 등등 그래픽 관련 일을 처리 Image processing unit (ISP) - 이미지 처리 어플리케이션들이 사용하는 일반적인 일들의 속도를 높이는데 사용 Diginal signal processor (DSP) - CPU보다 연산 집약적인 함수들을 다루는데 사용. 압축 해제 등등 Neural processing unit (NPU) - 하이엔드 스마트폰 등에서 기계학습 (A.I.) 속도를 높이는데 사용. 예를들어 음성인식, 이미지 처리 등등 Video encoder/decoder - 전력 효율적으로 비디오 파일이나 포맷을 변환하는 작업 수행 Secure Enclave - 암호화, 인증, 그 외 보안 관련 작업을 수행하는 영역 Unified memory - CPU, GPU와 다른 코어들이 빠르게 정보를 교환하는게 가능한 메모리 위 요소들이 왜 이미지나 영상 편집을 주로 하는 많은 사용자들이 M1 맥에서 엄청난 속도 향상을 느끼는지에 대한 이유중 하나입니다. 그런 사용자들이 하는 일 중 많은 부분을 특화된 하드웨어 위에서 직접적으로 돌릴 수 있기 때문이지요. 그것이 바로 값비싼 iMac이 비행기 이륙하는 소리를 내는 동안 저렴한 M1 맥 미니가 땀 한방울 안흘리고 대용량 비디오 파일을 인코딩 할 수 있는 이유입니다. **파란색** 부분은 여러개의 CPU 코어가 메모리에 접근하는것을 나타내며, **초록색** 부분은 엄청난 수의 GPU 코어가 메모리에 접근하는것을 나타낸다. 애플의 통합 메모리 아키텍쳐 (Unified Memory Architecture)는 뭐가 그렇게 특별할까?애플의 “Unified Memory Architecture” (UMA)는 이해하기에 약간 어려울 수 있습니다. (저 또한 처음 이 글을 적을 때 잘못 이해하고 있었습니다) 그 이유를 설명하기 위해서, 몇발자국 물러서서 바라 볼 필요가 있습니다. 오랜 시간동안 저렴한 컴퓨터 시스템은 CPU와 GPU를 하나의 칩(같은 실리콘 다이) 안에 가지고 있어왔습니다. 이러한 시스템은 느린것으로도 잘 알려져 있었습니다. 과거에는 “내장 그래픽(integrated graphics)” 이라 하면 “느린 그래픽(slow graphics)”과 동일한 의미로 사용되었을 정도입니다. 내장 그래픽이 느린데에는 다음과 같은 이유가 있었습니다. 우선 메모리 내에서 CPU와 GPU를 위해 별개의 영역이 예약되어야 했습니다. (역자: 내장그래픽을 쓰면 램 일부가 하드웨어 예약으로 잡힌다.) 만약 CPU가 GPU에서 사용되길 원하는 데이터 덩어리(chunk)가 있으면 단순히 “야 GPU, 내 메모리 이 부분에 있는 데이터 가져다 써” 라고 할 수 없었습니다. 그 대신, CPU는 데이터 덩어리를 통째로 다 복사하여 GPU가 제어하는 메모리 영역으로 넘겨주어야 했습니다. CPU는 데이터를 대량으로 제공받기 보다 **빠르게** 제공받기를 원한다. CPU와 GPU는 같은 방식으로 메모리를 제공받기를 원하지 않습니다. 좀 웃기긴 하지만 음식을 가지고 비유를 해 보겠습니다. CPU는 데이터가 담겨있는 식사를 웨이터가 아주 빠르게 서빙해 주길 바라지만, 데이터의 양에 대해서는 아주 관대합니다 (역: 작아도 상관 없다는 뜻). 웨이터가 롤러블레이드를 타고 아주 빠른 속도로 서빙을 하는 프랑스 레스토랑을 상상해 보세요. GPU는 이렇게 메모리를 제공받길 원한다. 아주 대용량으로, 많으면 많을수록 GPU는 행복해요~😋 그와 반대로 GPU는 웨이터가 느릿느릿하게 데이터를 서빙하는데에 대해서는 아주 관대합니다. 대신, GPU는 아주 거대한 양을 서빙받길 원합니다. GPU는 대량의 데이터를 집어삼키는데, 그 이유는 GPU가 많은 양의 데이터를 동시에 먹어치울 수 있는 초대형 병렬 처리 기기이기 때문입니다. 미국 패스트푸드 식당을 상상해 보세요. 음식이 도착할 때 까지는 좀 걸리지만 여러분이 앉아 있는 곳까지 3단 카트에 음식이 가득 실려 오고 있습니다. 이렇게 서로 다른 요구사항 때문에, CPU와 GPU를 같은 물리적ㅈ칩 위에 넣는것은 좋은 아이디어가 아니었습니다. 우리 GPU는 프랑스 식당에서 제공하는 적은 양의 음식을 먹다 굶어 죽을것입니다. 결과적으로 강력한 GPU를 SoC에 넣는것은 큰 의미가 없었습니다. 매우 작은 양의 데이터가 GPU에게 제공되는데, 그정도는 작고 가벼운 GPU로도 충분히 처리할 수 있었으니까요. 두번째 문제는 거대한 GPU는 많은 양의 열을 발생시키는데, 이 열을 해결하지 않고서는 CPU와 통합시킬 수 없다는 것입니다. 때문에 외장 그래픽 카드는 아래 사진처럼 무시무시한 쿨링 팬을 가진 거대한 짐승처럼 생기는 경향이 있습니다. 또한 욕심쟁이 외장 그래픽 카드에게 많은 양의 데이터를 제공할 수 있는 개별 메모리를 가지도록 디자인 되어 있습니다. GeForce RTX 3080 그게 바로 이러한 그래픽 카드가 높은 성능을 가지고 있는 이유이기도 하지만, 아킬레스건을 가지고 있기도 합니다. 바로 CPU가 사용하는 메모리로부터 데이터를 가져올 때 입니다. 이 과정은 컴퓨터의 마더보드에 있는 PCIe 버스(bus)라 불리는 구리 선을 통해 일어나게 됩니다. 완전 얇은 빨대를 통해 물을 빨아먹는다고 생각 해 보세요. 입에 도착은 빨리 하겠지만, 물이 들어오는 속도는 처참하겠지요? 애플의 통합 메모리 아키텍쳐 (Unified Memory Architecture)는 이전의 공유 메모리가 가졌던 단점 없이 이러한 문제를 모두 해결하고자 합니다. 애플은 다음과 같은 방법으로 이를 달성하였습니다. CPU나 GPU만을 위해 예약된 전용 메모리 공간이 따로 없습니다. 둘 다 같은 메모리를 사용하며, 복사가 필요하지 않습니다. 애플은 대량의 데이터를 제공하고, 동시에 빠르기까지 한 메모리를 사용합니다. 이는 컴퓨터 전문 용어로 low latency, high throughput 이라고 합니다. 덕분에 다른 종류의 메모리가 연결되 있어야 할 필요가 없습니다. 애플은 GPU의 와트 사용량을 낮춤으로써 상대적으로 강력한 GPU도 과열 문제 없이 SoC에 통합될 수 있게 하였습니다. 또한 ARM 칩 자체의 열 발생량이 적기 때문에, AMD나 인텔 CPU를 사용하는 같은 실리콘 다이에 비해 GPU가 발생시키는 열을 좀 더 수용할 수 있었습니다. 물론 통합 메모리(unified memory) 자체는 완전히 새로운 것이 아니라고 이야기 하는 사람이 있을 수 있습니다. 이전에 다른 시스템에서 이러한 것들이 사용된 적이 있는 것은 사실입니다. 하지만 M1에 비해 메모리 요구량이 그렇게 많지 않았습니다. 둘째로, Nvidia가 통합 메모리 라고 부르던 것은 사실 같은것이 아닙니다. Nvidia 세계에서 통합 메모리는 단지 분리된 CPU와 GPU 메모리 사이에서 자동으로 데이터를 양방향으로 복사 해 주는 소프트웨어와 하드웨어가 있음을 의미하였습니다. 즉 프로그래머의 관점에서 애플과 Nvidia의 통합 메모리는 같아 보일 수 있지만, 사실 물리적 관점에서는 둘은 같은것이 아닙니다. 물론 이러한 통합 메모리 전략에는 장단점이 존재합니다. 대역폭이 높은 메모리(대량의 데이터 제공)는 완전한 통합(integration)을 요구하는데, 이 경우 제품을 구매한 고객이 직접 메모리를 업그레이드 하는것이 불가능 해 집니다.하지만 애플은 SSD 디스크와의 통신을 매우 빠르게 만듦으로써 사실상 기존의 메모리처럼 작동하게 하여 이러한 문제를 해결하고자 합니다. 통합 메모리 이전 맥이 GPU를 사용하던 방법. 심지어 썬더볼트3 케이블을 통해 컴퓨터 외부의 그래픽 카드를 사용할 수 있었다. 미래에 M1맥북에도 이러한 것이 가능할 것 이라는 고찰도 있다. SoC가 그렇게 좋으면, 왜 인텔과 AMD는 이 전략을 따라하지 않을까?애플이 하고있는게 그렇게 좋은것이라면, 왜 모두가 이 방법을 하고 있지 않을까요? 사실 이미 어느정도 그렇게 하고 있습니다. 다른 ARM 칩 제조사들은 점점 더 많은 특화된 하드웨어를 넣고 있습니다. AMD또한 더 강력한 GPU를 그들의 칩 중 일부에 넣기 시작했으며, accelerated processing units (APU)를 통해 SoC와 비슷한 형태로 점차 옮겨가고 있는데, APU는 기본적으로 CPU 코어와 GPU 코어가 같은 실리콘 다이에 위치하는 칩 입니다. CPU와 GPU (Radeon Vega)를 하나의 실리콘 칩에 탑재한 AMD 사의 Ryzen Accelerated Processing Unit (APU). 하지만 IO-컨트롤러, 통합 메모리 등은 탑재하지 않았다. 그럼에도 아직 애플이 아닌 다른 기업들이 이를 하기 어려운 중요한 이유가 남아 있습니다. SoC는 근본적으로 하나의 온전한 컴퓨터가 들어가 있는 칩 입니다. 때문에 이러한 구조는 근본적으로 Dell, HP와 같은 실제 컴퓨터 제조사에 알맞는 형태입니다. 이를 자동차를 통한 비유로 좀 더 명확하게 설명해 보겠습니다. 여러분의 비즈니스 모델이 자동차 엔진을 만들고 파는 것 이라면, 완전한 자동차를 만들어 파는것과는 아주 큰 사업적인 차이가 있을 것입니다. 반대로 ARM에게 있어서 이는 큰 문제가 아닙니다. Dell이나 HP 같은 컴퓨터 제조사들은 그들이 만드는 SoC의 CPU를 위해 단순히 ARM의 지적 재산권 라이센스를 발급받기만 하고, SoC에 필요한 다른 특화된 하드웨어의 IP를 구매해 합치기만 하면 되기 때문이지요. 그리고 나서, GlobalFoundries나 TSMC같이 오늘날 AMD와 애플의 칩을 제조하는 반도체 제조 공정들에게 완성된 디자인을 전달하기만 하면 됩니다. 대만에 있는 TSMC 반도체 파운드리. TSMC는 AMD,애플, Nvidia, 퀄컴 등의 기업을 위해 칩을 제조한다. 여기서 인텔과 AMD의 비즈니스 모델에 큰 문제점이 발생합니다. 그들의 비즈니스 모델은 사람들이 PC의 마더보드에 바로 끼울 수 있는 범용 CPU (general-purpose CPU)를 판매하는 것 입니다. 이 덕분에 컴퓨터 제조사들은 단순히 마더보드, 메모리, CPU, 그래픽 카드를 각각의 제조사로부터 따로 구매하여 하나의 완성 제품으로 판매할 수 있습니다. 하지만 우리는 그러한 세상으로부터 빠르게 옮겨가고 있습니다. 새로운 SoC 세계에서는 각각의 제조사에서 만든 서로다른 물리적 구성요소들을 조립하지 않습니다. 그 대신, 여러 제조사들이 가지고 있는 IP (지적 재산권, intellectual property)를 조립하게 됩니다. 제조사들은 그래픽 카드, CPU, 모뎀, IO 컨트롤러, 그리고 SoC에 포함될 수 있는 많은 다른 것 들 각각의 설계 (design)을 구매하여 실제 판매할 SoC를 디자인 하게 됩니다. 그 다음 이를 제조 할 제조공정 (foundary)을 구하게 됩니다. 이제 여기서 큰 문제가 발생합니다. 바로 인텔, AMD, Nvidia는 그들의 지적 재산권을 Dell이나 HP가 그들의 컴퓨터를 위한 SoC를 만들 수 있도록 라이센스를 제공해 주지 않는다는 것 입니다. 물론 인텔과 AMD가 완성품 SoC를 만들어 팔기 시작할 수 도 있습니다. 하지만 그러한 SoC가 무엇을 포함하고 있어야 할까요? PC 제조사들마다 SoC가 가지고 있어야 할 구성 요소에 대한 생각이 다를 수 있습니다. 모든 구성 요소들은 소프트웨어 지원이 필요하기 때문에, 어떠한 특화된 칩들이 포함되어야 되는지에 대해 인텔, AMD, 마이크로소프트, 그리고 PC 제조사들 간의 의견 충돌이 발생할 수 있을 것입니다. 하지만 애플에게 이 문제는 아주 간단합니다. 애플은 모든것을 직접 관리합니다. 예를들어 애플은 개발자들이 머신러닝 관련 코드를 작성할 수 있도록 Core ML 라이브러리를 만들어 제공합니다. Core ML이 애플의 CPU에서 돌아가는지 Neural Engine에서 돌아가는지는 구현 세부사항 (implementation detail)이기 때문에 개발자들은 이에 대해 신경 쓸 필요가 없습니다. (역: 애플은 하드웨어 뿐만 아니라 소프트웨어 및 운영체제 까지 직접 제조한다는 의미) 빠른 CPU를 만드는데 관한 근본적인 어려움지금까지 요약으로 혼합적인 컴퓨팅 (heterogeneous computing)이 그 이유 중 하나이지만, 온전히 그것 덕분은 아닙니다. Firestorm이라 불리는 M1의 범용 CPU 코어는 정말 빠릅니다. 이는 과거에는 AMD나 인텔의 코어에 비해 많이 약했던 ARM CPU의 주요 변형판(major deviation) 입니다. 반면에 Firestorm은 대부분의 인텔 코어를 능가하며, 가장 빠른 AMD Ryzen 코어를 거의 능가하는 모습을 보여줍니다. 이전까지의 상식으로는 이러한 일은 절대 발생하지 않을 것이라 생각되었죠. 무엇이 Firestorm을 빠르게 만드는지를 이야기 하기 전에, CPU를 빠르게 하는 요소들이 무엇이 있는지를 먼저 알아보면 도움이 될 것입니다. 일반적인 통념으로 CPU 속도 증가는 아래 두가지 전략을 조합하여 달성할 수 있습니다. 연속된 instruction을 더 빨리 순차적으로 수행 동시에 다량의 insruction을 병렬 수행 1980년대로 돌아가 보면, 단순히 클럭 스피드를 높이기만 해도 instruction 수행이 더 빨리 끝났습니다. 한번의 클럭 싸이클 (clock cycle) 마다 컴퓨터는 무언가 하나를 수행하였습니다. 그런데 이 무언가 라는것이 꽤나 작고 사소한 것일 수 있습니다. 때문에 하나의 instruction이 여러개의 더 작은 task(역: 위의 무언가)로 이루어져 있을 수 있기 때문에, 때로는 여러번의 클럭 싸이클을 지나야만 하나의 instruction을 수행할 수 도 있습니다. 하지만 오늘날에는 클럭 스피드를 높이는것이 거의 불가능해 졌습니다. 그것이 바로 지난 몇년간 사람들이 계속해서 이야기 해 오는 “무어의 법칙의 끝”에 관한 것 입니다. 때문에 빠른 CPU를 만드는것은 이제 동시에 최대한 많은 instruction을 수행하는 것에 관한것이 되었습니다. Multi-core 또는 Out-of-Order processors?이에 대하여 두가지 접근법이 있습니다. CPU 코어 갯수를 더 늘리자. 각각의 코어는 독립적이고 병렬적으로 일한다. 각각의 CPU 코어가 동시에 여러개의 instruction을 수행할 수 있게 만들자. 소프트웨어 개발자에게 있어서, 코어 갯수를 늘리는것은 쓰레드 갯수를 늘리는 것과 같습니다. 각각의 CPU 코어는 하드웨어판 쓰레드 처럼 작동합니다. 만약 쓰레드가 무엇인지 모르신다면, 쓰레드는 어떠한 일(task)을 수행하는 하나의 프로세스라고 생각할 수 있습니다. 두개의 코어가 있다면, 하나의 CPU는 두개의 서로다른 일을 동시에(concurrently) 수행할 수 있습니다. 두개의 쓰레드가 있는것 처럼요. task는 두가지 별개의 프로그램이 메모리에 올라가 있거나, 같은 프로그램이 두번 실행되는것으로 생각될 수 있습니다. 각 쓰레드는 현재 프로그램이 실행되고 있는 instruction 위치가 어디인지 등을 저장하는 정보를 저장할 필요가 있습니다. 각 쓰레드는 실행 중간 산물을 개별로 관리하여 저장할 수 도 있습니다. 원칙적으로, 하나의 프로세스는 하나의 코어와 여러개의 쓰레드를 실행할 수 있습니다. 이 경우, 프로세스는 쓰레드를 전환(switch)할 때 현재 실행중인 쓰레드를 정지(halt)하고 진행 상황을 저장합니다. 그리고 나중에 정지되었던 쓰레드로 돌아와 다시 실행하게 됩니다. 그러나 이러한 멀티 쓰레딩은 아래와 같은 경우가 자주 발생하지 않는 이상 그렇게 큰 성능 향상을 가져오지는 않습니다. 사용자로부터 입력 값을 대기 느린 네트워크 연결로부터 데이터를 수신 이 글에서는 이러한것을 소프트웨어 쓰레드라고 부르기로 하겠습니다. 반대로 하드웨어 쓰레드는 속도를 높이기 위해 실제로 여러개의 물리적 CPU가 사용되는것을 의미합니다. 쓰레드의 문제점은 소프트웨어 개발자가 멀티 쓰레드 코드라고 불리는 형태로 코드를 작성해야 한다는 것 입니다. 이것은 때때로 쉽지 않은 일인데, 옛날에는 이러한 방법이 코드를 작성할때 가장 힘든 일 중 하나이기도 하였습니다. 하지만 서버 소프트웨어를 멀티 쓰레딩으로 만드는것은 상대적으로 쉽게 여겨집니다. 이 경우에는 단순히 각각의 사용자 요청을 처리하는 개별 쓰레드를 만들면 되기 때문이지요. 그렇기 때문에 이 경우 많은 수의 코어를 가지는 것은 성능에 확실히 큰 도움이 됩니다. 특히 클라우드 서비스의 경우 더 그렇습니다. 클라우드 컴퓨팅을 위해 디자인 된 128개의 코어가 장착된 Ampere Altra Max ARM CPU, 이 경우 다수의 하드웨어 쓰레드가 큰 이점이 된다. 그것이 바로 Ampere같은 ARM CPU 제조사들이 Altra Max같이 128개의 코어가 있는 미친 CPU를 만드는 이유입니다. 이 칩은 클라우드를 위해 특별히 만들어 진 칩 입니다. 클라우드 서비스에서는 고성능 싱글코어 성능이 필요하지 않은데, 클라우드 서비스에서는 같은 전력 소모 대비 최대한 많은 쓰레드를 유지하여 동시에 최대한 많은 사용자의 요청을 처리하는것이 중요하기 때문입니다. 다수의 코어를 가지고 있는 ARM CPU에 관해서 더 알아보고 싶으시다면 다음 글을 읽어보시길 추천드립니다. Are Servers Next for Apple? 이와 반대로 애플은 전혀 반대의 사용성을 가지는 위치에 서있습니다. 애플은 한명의 유저가 사용하는 디바이스를 제조합니다. 다수의 쓰레드를 가지는것은 그다지 이점으로 작용하지 않지요. 애플이 만드는 기기는 게이밍, 영상편집, 개발 등의 작업에 주로 사용이 됩니다.애플은 아름답고 반응성 있는 그래픽과 애니메이션을 가지는 데스크탑을 원합니다. 데스크탑 어플리케이션은 일반적으로 다수의 코어를 활용할 수 있도록 만들어 지지 않습니다. 예를들어 컴퓨터 게임은 8개 정도의 코어를 통해서는 어느정도 이점을 얻을 수 있지만, 128개의 코어 같은건 진짜 낭비에 불과합니다. 그 대신 갯수는 적더라도 각각의 성능이 더 강력한 코어가 더 적절하지요. 비 순차적 실행 (Out-of-Order Execution) 이 동작하는 방법더 강력한 성능의 코어를 만들기 위해, 하나의 코어가 더 많은 수의 instruction을 병렬적으로 수행하게 만들 필요가 있습니다. Our-of-Order execution (OoOE)은 멀티 쓰레딩과 같은 기법 없이 동시에 여러 instruction을 수행하는 한가지 방법입니다. 또 다른 방법에 대해 알아보고 싶으시면 다음 글을 읽어보시길 추천드립니다: Very Long Instruction Word Microprocessors 개발자들은 자신의 코드가 OoOE를 활용할 수 있도록 특별히 신경써서 작성해야 할 필요가 없습니다. 개발자의 관점에서 보면 그냥 각각의 코어가 더 빨리 작동하는것처럼 보일 뿐 입니다. 여기서 이 방법은 여러개의 하드웨어 쓰레드를 가지는 것 과는 다른 방법임을 명심해 주세요. 여러분이 해결하고자 하는 문제에 따라, 하드웨어 쓰레드와 OoOE를 둘 다 활용할 수 도 있습니다. OoOE가 어떻게 작동하는지 알기 위해, 메모리에 관해 몇가지 알아야 할 것들이 있습니다. 특정 메모리 위치 한 곳에 존재하는 데이터의 값을 불러오는것은 느립니다. 하지만 CPU는 한 메모리 위치에서 여러 연속된 바이트를 동시에 불러올 수 있습니다. 따라서 메모리에서 특정 1 바이트를 읽어오는 것은 그 뒤에 붙어서 저장되어 있는 100 바이트를 추가로 더 불러오는 것과 그렇게 큰 차이가 나지 않습니다. 노르웨이에 있는 온라인 상점인 Komplett.no의 창고에 있는 로봇 짐꾼들. 한가지 비유를 들어 보겠습니다. 창고에 있는 짐나르는 로봇을 상상해 봅시다. 위 사진에서처럼 작은 빨간 로봇일 수 있겠지요. 여러곳에 퍼져 있는 장소에 이리저리 옮겨 다니는 것은 시간이 꽤 걸릴 것 입니다. 하지만 서로 인접한 구역에 있는 물건들을 집어 올리는것은 꽤 빨리 할 수 있을 것입니다. 컴퓨터의 메모리 또한 매우 비슷합니다. 서로해 있는 메모리 구역은 그 내용을 빨리 불러 올 수 있습니다. 데이터는 우리가 데이터 버스(databus)라고 부르는 것에 의해 여기저기로 보내 집니다. 이는 메모리와 CPU의 여러 부분에 연결되어 데이터가 옮겨지는 길이나 파이프 정도로 생각할 수 있습니다. 실제로 데이터버스는 그냥 전기를 전도하는 구리 선에 불과합니다. 데이터버스가 충분히 넓으면 동시에 여러 바이트의 데이터를 보낼 수 있습니다. 이를 통해 CPU는 실행해야 할 instruction들을 동시에 왕창 buffer에 받을 수 있습니다. 하지만 그 instruction들은 하나하나 순차적으로 실행되도록 작성되어 있지요. 현대적인 microprocessor들은 Out-of-Order execution (OoOE)라고 불리는 것을 수행합니다. 즉, 현재 CPU에 불러와져 있는 insturction들이 저장되어 있는 buffer를 보며, 어느 것이 어디에 의존성을 가지고 있는지를 빠르게 분석합니다. 아래 예시를 참고해 봅시다. 12301: mul r1, r2, r3 // r1 &lt;- r2 * r302: add r4, r1, 5 // r4 &lt;- r1 + 503: add r6, r2, 1 // r6 &lt;- r2 + 1 곱셈은 상대적으로 느린 연산입니다. 그러니 한 사이클 이상이 걸린다고 생각해 봅시다. 두번째 instruction에서 연산을 수행하려면 먼저 r1에 저장될 연산 결과를 알아야 하기 때문에, 첫번째 instruction이 끝날 때 까지 그저 기다려야 할 것 입니다. 하지만 03번 줄의 세번째 instruction은 이전 instruction들의 결과에 대해 의존(depend)하고 있지 않습니다. 따라서 비 순차적 실행을 지원하는 프로세서는 03번 insturction을 병렬 수행할 수 있습니다. 그렇지만 우리는 실제로 사용될 수백개의 instruction들을 가지고 이야기를 해야하겠지요? CPU는 그런 insturction들 사이에서의 모든 의존 관계를 알아낼 수 있습니다. CPU는 각 instruction들의 인풋을 조사함으로써 의존관계를 분석합니다. 인풋이 하나 이상의 다른 instruction의 아웃풋에 의존하는가? 여기서 인풋과 아웃풋은 이전 계산의 결과를 저장하고 있는 레지스터를 의미합니다. 예를들어 add r4, r1, 5 instruction은 r1 레지스터에 저장되어 있는 인풋에 의존하고 있으며, 그 값은 mul r1, r2, r3 instruction을 통해 결정됩니다. 이러한 관계들을 연결하여 아주 길고 복잡한 그래프를 만들 수 있고, CPU는 이 그래프를 활용하게 됩니다. CPU는 그런 그래프의 노드들을 분석하여 어느 instruction이 병렬 수행 될 수 있고, 어느 지점에서 의존하고 있는 여러개의 연산 결과를 기다려야 하는지를 결정할 수 있습니다. 많은 instruction들이 일찍 실행이 끝나겠지만, 그 결과를 바로 레지스터에 반영할 수는 없습니다. 그랬다가는 연산 결과를 잘못된 순서로 제공해버릴 위험이 있기 때문입니다. (역: 뒤에 끝난 instruction이 오히려 먼저 레지스터에 반영되는 경우) OoOE 밖의 세상에서는, 마치 instruction이 발행된 순서대로 실행 된 것처럼 보여야 합니다. 스택과 같이, CPU는 끝나지 않은 instruction에 닿을 때 까지 완료된 instruction을 위에서부터 순서대로 pop 하게 됩니다. 기본적으로 병렬성은 두가지 형태로 제공됩니다. 개발자가 코드를 작성할 때 명시적으로 다루어야 하는 형태와 완전히 보이지 않는 형태입니다. 물론 두번째 것은 마법과도 같은 비순차 실행을 담당하는 수많은 CPU 트랜지스터에 의존하고 있긴 합니다. 때문에 이는 트랜지스터 수가 적은 작은 사이즈의 CPU에는 적합한 해결책이 아닙니다. 그리고 월등히 좋은 비순차 실행이 바로 M1에 탑재되어 있는 Firestorm 코어가 기똥차게 빠르고 유명해 질 수 있었던 이유입니다. Firestorm의 비 순차 실행은 아마 인텔과 AMD가 절대 따라잡을 수 없을 정도로 그 무엇보다 강력합니다. 왜 그런지를 이해하기 위해 우리는 좀 더 기술적으로 깊게 들어가야 할 필요가 있습니다. ISA Instructions vs Micro-Operations이전 파트에서 저는 비 순차적 실행이 어떻게 동작하는지에 관해 몇가지 자세한 사항들을 생략하였습니다. 메모리에 로딩되는 프로그램은 x86, ARM, PowerPC, 68K, MIPS, AVR 등과 같은 특정 Instruction-Set Arcitectures (ISA)를 위해 디자인 된 기계어(machine code)들로 이루어 져 있습니다. 예를들어 24라는 메모리 위치에서 숫자를 레지스터로 불러오는 x86 instruction은 아래와 같이 작성할 수 있습니다. 1MOV ax, 24 x86은 ax,bx,cx,dx 라고 불리는 레지스터들을 가지고 있습니다 (앞에서 언급했다 시피 이들은 연산 수행 대상이 되는 CPU 내부의 메모리 셀 입니다). 하지만 위와 대등한 코드를 ARM instruction으로 표현하면 다음과 같이 생겼습니다. 1LDR r0, 24 AMD와 인텔 프로세서는 x86 ISA를 이해하지만, M1과 같은 애플 실리콘 칩은 ARM Instruction-Set Architecture (ISA)를 이해합니다. 하지만 내부적으로 CPU는 프로그래머에게 보이지 않는 완전히 다른 instruction-set을 통해 작동합니다. 이러한 instruction-set은 micro-operations 이라고 불립니다 (micro-ops또는 μops). 이것들이 바로 비 순차적 실행을 하는 하드웨어가 다루는 것 들 입니다. 그런데 왜 OoOE 하드웨어가 그냥 일반적인 기계어 instruction을 다룰 수 없는 것일까요? 그 이유는 바로 CPU가 instruction을 병렬 수행하기 위해서는 아주 많은 별도의 부가 정보를 instruction에 덧붙여 저장해야 하기 때문입니다. 때문에 일만적인 ARM instruction은 32-bit 크기이지만, micro-op은 더 길어질 수 도 있습니다. mirco-op은 자신의 실행 순서 관한 정보도 포함하고 있지요. 12301: mul r1, r2, r3 // r1 &lt;- r2 * r302: add r4, r1, 5 // r4 &lt;- r1 + 503L add r6, r2, 1 // r1 &lt;- r2 + 1 instruction 01: mul과 03: add를 병렬 수행 하는 경우를 생각해 봅시다. 둘 다 자신의 실행 결과를 레지스터 r1에 저장합니다.만약 03: add의 실행 결과가 01: mul보다 먼저 쓰여진다면, instruction 02: add는 잘못된 값을 인풋으로 받게 될 것 입니다.그러므로 instruction의 순서를 추적하는 것은 아주 중요합니다. 각각의 실행 순서는 micro-op에 포함되어 저장됩니다.또한 instruction 02: add가 01: mul의 아웃풋에 의존하고 있다는 정보 같은것도 함께 저장되게 됩니다. 그리고 이것 왜 micro-ops를 가지고 직접 프로그램을 작성할 수 없는 이유이기도 합니다. micro-ops는 각 microprocessor의 내부적인 세부 정보들을 많이 포함하고 있습니다.두개의 다른 ARM 프로세서는 완전히 다른 micro-ops를 내부적으로 가질 수 있습니다. micro-ops 과 관련된 내용에 대해 더 알고 싶으시다면 다음 글을 읽어보시길 추천드립니다: Very Long Instruction Word Microprocessors 또한, micro-ops는 주로 CPU가 다루기에 더 쉽습니다. 왜냐구요? micro-ops는 딱 하나의 간단하고 단순한 일(task)을 수행하기 때문입니다.일반적인 ISA instruction들은 여러가지 일이 발생하게 하는 더 복잡한 경우가 많고, 때문에 하나 이상의 micro-ops로 번역되는 경우가 많습니다.따라서 “micro”라는 이름은 그들이 수행하는 작은 일(task) 때문에 붙여진 것이며, 메모리 내의 instruction 크기가 작기 때문에 그렇게 지어진 것이 아닙니다. CISC CPU들 같은 경우에는 micro-ops 사용하는 것 외에는 거의 다른 대안이 없습니다. 그렇지 않으면 크고 복잡한 CISC instruction들의 특성 때문에 pipeline과 OoOE는 사실상 불가능할 것 이니까요. RISC CPU들은 다른 선택의 여지가 있습니다. 그래서 예를들어, 작은 ARM CPU같은 경우 micro-ops를 아예 사용하지 않기도 합니다. 하지만 그 경우에 OoOE와 같은 일들을 못하게 됨을 의미합니다. 왜 AMD나 인텔의 OoOE는 M1의 것보다 더 안좋을까?그런데 이쯤되면 “근데 이게 왜 중요하지?” 라는 생각이 들 수 있겠지요.이렇게 자세한 내용들이 애플이 AMD와 인텔보다 더 우위에 있는지를 이해하는데 중요할까요? 물론 그렇습니다. 그 이유는 바로 CPU가 빠르게 연산을 수행하는것은 얼마나 빨리 micro-operation들이 저장되는 버퍼를 채울 수 있냐에 달려있기 때문입니다.만약 더 큰 버퍼를 가지고 있다면 OoOE 하드웨어는 병렬 수행 될 수 있는 instruction들을 더 손쉽게 찾을 수 있을것입니다.하지만 아무리 큰 instruction 버퍼를 가지고 있다고 하더라도, 버퍼를 빨리 채울 수 없으면 의미가 없겠지요. instruction 버퍼를 빠르게 채울 수 있는 능력은 기계어(machine code)를 빠르게 micro-ops로 쪼갤 수 있는 능력에 달려 있습니다.이러한 일을 수행하는 하드웨어 유닛을 decoders 라고 부릅니다. 드디어 M1의 핵심 특징(killer feature)에 대해 이야기 할 차례입니다.인텔과 AMD의 가장 크고 빠릿한 microprocessor는 열심히 instruction을 micro-ops로 쪼개느라 바쁜 총 4개의 decoder를 가지고 있습니다. 하지만 이 친구들은 M1에게는 적수가 되지 않습니다. M1은 들어보지 못한 숫자의 decoder를 가지고 있지요, 무려 8개 입니다.이쪽 업계의 그 어느 것들보다 훨씬 더 많은 갯수이지요.이는 곧 M1이 instruction buffer를 훨씬 더 빨리 채울 수 있음을 의미합니다. 이를 다루기 위해 M1은 또 일반적인 것보다 3배는 더 큰 버퍼를 가지고 있습니다. 왜 인텔과 AMD는 instruction decoder 갯수를 늘릴 수 없을까?여기가 바로 RISC가 복수를 시작하는 곳이며, M1 Firestorm이 ARM RISC 아키텍처를 채택한게 중요해 지는 순간입니다. 아시다 시피, x86 instruction은 1-15 바이트 사이의 임의의 길이를 가질 수 있습니다.RISC instruction은 고정된 길이를 가집니다. 모든 ARM instruction은 4바이트 길이입니다. 이게 왜 중요할까요? 왜냐하면 모든 instruction들이 같은 길이를 가지는 경우, 연속된 bytes 스트림을 쪼개어 8개의 decoder들에게 병렬적으로 제공하는것은 어렵지 않기 때문입니다. 반면 x86 CPU의 경우, decoder는 어디가 다음 instruction이 시작하는 위치인지를 알 방법이 없습니다.각 instruction을 분석해서 그 길이가 얼마나 되는지를 실제로 분석하는 수 밖에 없지요. (역: 이때문에 CISC에서는 같은 바이트 값이라도 위치에 따라 다르게 해석된다) 인텔과 AMD가 이를 해결하는 주먹구구식 방법은 그냥 instruction의 시작점으로 가능한 모든 위치로 decode를 시도해 보는 것입니다.이는 곧 x86 칩들이 수많은 잘못된 예측과 버려야 하는 실수들을 마주해야 함을 의미합니다.이는 또한 decoder를 더 추가하는게 어려울 정도로 복잡하고 베베 꼬인 decoder 단계를 만들었습니다.하지만 애플에게 있어서는 decoder를 추가하는게 그렇게 큰 일이 아닙니다. 사실, decoder를 더 추가하는것은 다른 수많은 문제들을 야기하기 때문에, AMD에 따르면 자기들은 사실상 4개가 최대 한계치라고 합니다. 이것이 바로 M1 Firestorm 코어가 AMD와 인텔 CPU와 같은 클럭 스피드인데도 두배나 많은 instruction을 처리할 수 있는 이유입니다. 물론 CISC instruction은 더 많은 수의 micro-ops로 변환된다고 지적할 수 도 있습니다.예를들어 모든 x86 instruction들이 2개의 micro-ops로 변환되고 ARM instruction은 1개의 micro-ops로 변환된다고 치면, 네개의 x86 decoder는 같은 클럭 싸이클 동안 8개의 decoder가 있는 ARM CPU와 같은 갯수의 micro-ops를 생산할것입니다. 근데 이것마저 실제로는 그렇지 않습니다. 고수준으로 최적화 된 x86코드는 여러개의 micro-ops로 번역되는 복잡한 CISC instruction을 거의 사용하지 않습니다.사실 대부분은 그냥 1개의 micro-ops로 번역됩니다. 하지만 이러한 모든 복잡하지 않은 x86 instruction은 그다지 인텔과 AMD에게 도움이 되지 않습니다.왜냐하면 15바이트 크기의 instruction이 흔하지 않다고 하더라도, decoder는 여전히 그것들을 처리할 수 있도록 만들어 져야 하기 때문입니다.이는 필연적으로 AMD와 Intel이 decoder를 추가하는것을 저해하는 복잡성을 야기합니다. 그래도 AMD의 Zen3 코어는 빠르잖아요 그쵸?제가 기억하는 바로 성능 벤치마크에 의하면 Zen3라고 불리는 최신 AMD CPU 코어는 Firestorm 코어보다 살짝 더 빠릅니다.근데 여기서 분위기를 깨는 친구가 있죠. 그건 Zen3 코어가 5 GHz 클럭 스피드를 가지기 때문입니다. Firestorm 코어는 3.2 Ghz 클럭 스피드를 가지고 있습니다.Zen3는 Firestorm보다 60% 빠른 클럭 스피드를 갖고 있음에도 불구하고 아주 살짝 겨우 이기는 정도입니다. 그러면 애플은 왜 클럭 스피드를 더 높이지 않는것일까요?그 이유는 바로 높은 클럭 스피드는 칩이 열을 더 많이 발생하게 만들기 때문입니다.이것은 애플이 내세우는 핵심 장점 중 하나입니다.애플의 컴퓨터는 인텔과 AMD와는 다르게 쿨링이 거의 필요하지 않습니다. 본질적으로, Firestorm 코어는 정말 Zen3 코어보다 더 뛰어나다고 할 수 있겠습니다.Zen3는 더 많은 전류를 소모하고 훨씬 열을 많이 발생함으로써 겨우 비비고 있는 중이니까요.애플이 그냥 선택하지 않기로 한 길이지요. 만약 애플이 더 높은 성능을 원했다면 그냥 더 많은 코어를 추가하였을 것입니다.이를 통해 와트 사용량은 낮추면서도 더 높은 성능을 제공할 수 있을것입니다. 미래AMD와 인텔은 자신들 스스로를 두가지 절벽에 몰아넣은 것 처럼 보입니다. 둘다 혼합적 컴퓨팅과 SoC 디자인을 쉽게 추구할 수 있는 비즈니스 모델을 가지고 있지 않습니다. 둘다 오래된(legacy) x86 CISC instruction set은 이제 OoO 성능을 개선하기 어렵게 만드는, 그들을 쫓는 사냥꾼이 되어버렸습니다. 이에 관한 글: Intel, ARM and the Innovators Dilemma 그래도 이게 게임 오버를 뜻하지는 않습니다.인텔과 AMD는 클럭 스피드를 높이고, 더 많은 쿨링을 사용하고, 코어 갯수를 높이고, CPU caches를 늘리는 등을 할 수 있습니다.하지만 둘 모두 불리한 위치에 있는것은 사실입니다.특히 인텔은 최악의 상황에 놓여있는데, 그들의 코어가 이미 Firestorm한테 가뿐히 패배하였단 점과, 그들이 SoC 솔루션에 포함시킬 수 있는 GPU는 아주 구리다는 것입니다. 또한 더 많은 수의 코어에 투자하는것의 문제는 일반적인 데스크탑 업무에는 많은 수의 코어를 통해서 얻을 수 있는 효과가 극미하다는 점 입니다.물론 많은 수의 코어가 서버에게는 아주 좋습니다. 그런데 여기서는 또 Amazon이나 Ampere같은 기업들이 128개의 코어를 가진 괴물 CPU로 공세를 가하고 있습니다.이건 마치 서부전선과 동부전선에서 동시에 전쟁을 치루는 느낌이네요. 하지만 AMD와 인텔에게는 다행스럽게도, 애플은 자기네 칩을 시장에다 직접 판매하지는 않습니다.그래서 PC 사용자들은 어떻게든 인텔과 AMD가 제공하는것 중에서 골라서 써야하지요.PC 유저들이 아예 다른 배를 타버릴수도 있겠지만(역: 맥 생태계로 넘어간다는 뜻), 그 과정은 아주 느릴것입니다.이미 많은 돈을 투자한 플랫폼을 쉽게 떠나지는 않으니까요. 그러나 어떤 플랫폼에도 깊게 투자하지 않고 쓸 수 있는 돈이 많은 젊은 전문가들은, 앞으로 점점 더 애플을 사용하며 프리미엄 시장에 대한 그들의 지분을 늘려가고, 결과적으로 전체 PC 시장에서의 이익에서 차지하는 비중을 높일 수도 있을 것입니다. (역: 아직 PC 생태계에 정착하지 않은 돈많은 사람들은 시작부터 애플 생태계로 갈 수도 있으며, 그 숫자가 비중이 커질 수도 있다는 뜻) 요약 SoC이라서 빠르다. Unified Memory RAM을 대체할 정도로 빠른 SSD 대신 사용자가 직접 업그레이드가 불가능 (근데 맥북은 원래 안되지 않나?) ARM 프로세서가 발열이 적어서 GPU가 내는 열을 좀 더 수용할 수 있다. OoOE에서 M1이 굉장히 큰 이점을 가지고 있다. RISC CPU인 ARM 기반 프로세서 덕분에 decoder 갯수가 훨씬 더 많음 이러한 것들은 애플이 하드웨어, 소프트웨어를 모두 직접 만드는 “컴퓨터 제조사”라서 가능한 것! 이게 가능한 회사는 현재는 애플밖에 없다. 역시 애플 충성충성!!바로 M1 맥북 예약구매 하러 갑니다!!","link":"/2020/12/14/20201214-why-is-apple-m1-chip-so-fast/"}],"tags":[{"name":"webpack","slug":"webpack","link":"/tags/webpack/"},{"name":"node.js","slug":"node-js","link":"/tags/node-js/"},{"name":"css","slug":"css","link":"/tags/css/"},{"name":"rollup","slug":"rollup","link":"/tags/rollup/"},{"name":"svelte","slug":"svelte","link":"/tags/svelte/"},{"name":"meteor","slug":"meteor","link":"/tags/meteor/"},{"name":"gRPC","slug":"gRPC","link":"/tags/gRPC/"},{"name":"Rust","slug":"Rust","link":"/tags/Rust/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"Go","slug":"Go","link":"/tags/Go/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"Javascript","slug":"Javascript","link":"/tags/Javascript/"},{"name":"gdb","slug":"gdb","link":"/tags/gdb/"},{"name":"debug","slug":"debug","link":"/tags/debug/"},{"name":"vscode","slug":"vscode","link":"/tags/vscode/"},{"name":"bash","slug":"bash","link":"/tags/bash/"},{"name":"shellscript","slug":"shellscript","link":"/tags/shellscript/"},{"name":"crawling","slug":"crawling","link":"/tags/crawling/"},{"name":"cli","slug":"cli","link":"/tags/cli/"},{"name":"macbook","slug":"macbook","link":"/tags/macbook/"},{"name":"m1","slug":"m1","link":"/tags/m1/"}],"categories":[{"name":"Development","slug":"Development","link":"/categories/Development/"},{"name":"Web","slug":"Development/Web","link":"/categories/Development/Web/"},{"name":"Programming Language","slug":"Programming-Language","link":"/categories/Programming-Language/"},{"name":"Node.js","slug":"Development/Node-js","link":"/categories/Development/Node-js/"},{"name":"Tools","slug":"Development/Tools","link":"/categories/Development/Tools/"},{"name":"Terminal","slug":"Development/Terminal","link":"/categories/Development/Terminal/"},{"name":"Article","slug":"Article","link":"/categories/Article/"}]}